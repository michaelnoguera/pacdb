{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DuckDB Notebook\n",
    "\n",
    "This notebook generates a bunch of raw outputs, without applying PAC, to be consumed by a second stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE = False, so we will load saved output from files rather than recomputing.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "EXPERIMENT = 'pac-duckdb-q2-inner'\n",
    "OUTPUT_DIR = f'./outputs/{EXPERIMENT}'\n",
    "GENERATE = False\n",
    "USE_EVEN_NUMBER_OF_INPUT_ROWS = False\n",
    "\n",
    "if GENERATE:\n",
    "    print(\"GENERATE = True, so we will generate new samples.\")\n",
    "else:\n",
    "    print(\"GENERATE = False, so we will load saved output from files rather than recomputing.\")\n",
    "\n",
    "import os\n",
    "from typing import List\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "import duckdb\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "\n",
    "# duckdb load data/tpch/tpch.duckdb\n",
    "#con = duckdb.connect(database='data/tpch/tpch.duckdb', read_only=True)\n",
    "con = duckdb.connect(database=':memory:')\n",
    "tables = [\"customer\", \"lineitem\", \"nation\", \"orders\", \"part\", \"partsupp\", \"region\", \"supplier\"]\n",
    "#tables = [\"lineitem\", \"orders\"]\n",
    "for t in tables:\n",
    "    con.execute(f\"CREATE TABLE {t} AS SELECT * FROM 'data/tpch/{t}.parquet'\")\n",
    "\n",
    "lineitem_df = con.execute(\"SELECT * FROM lineitem\").fetchdf()\n",
    "orders_df = con.execute(\"SELECT * FROM orders\").fetchdf()\n",
    "\n",
    "row_count = lineitem_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the table of random samples\n",
    "# to use, join it with the lineitem table (for specific sample # s) and filter to just the\n",
    "# rows where random_binary = 1.0\n",
    "# This will give us a 50% sample of the lineitem table for each sample # s\n",
    "\n",
    "SAMPLES = 1024\n",
    "assert SAMPLES % 2 == 0, \"SAMPLES must be even to create complementary samples.\"\n",
    "\n",
    "random_samples = con.execute(f\"\"\"\n",
    "DROP TABLE IF EXISTS random_samples;\n",
    "\n",
    "CREATE TABLE random_samples AS\n",
    "WITH sample_numbers AS MATERIALIZED (\n",
    "    SELECT range AS sample_id FROM range({SAMPLES//2})\n",
    "), random_values AS MATERIALIZED (\n",
    "    SELECT \n",
    "        sample_numbers.sample_id,\n",
    "        supplier.rowid AS row_id,\n",
    "        (RANDOM() > 0.5)::BOOLEAN AS random_binary\n",
    "    FROM sample_numbers\n",
    "    JOIN supplier ON TRUE  -- Cross join to duplicate rows for each sample\n",
    ")\n",
    "SELECT\n",
    "    sample_id,\n",
    "    row_id,\n",
    "    random_binary\n",
    "FROM random_values\n",
    "UNION ALL\n",
    "SELECT -- select the complementary samples too\n",
    "    ({SAMPLES//2}) + sample_id,\n",
    "    row_id,\n",
    "    NOT random_binary  -- Inverse the random_binary to get the complementary sample\n",
    "FROM random_values\n",
    "ORDER BY sample_id, row_id;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_sizes = con.execute(\"\"\"\n",
    "#SELECT sample_id, SUM(random_binary) AS sample_size\n",
    "#FROM random_samples\n",
    "#GROUP BY sample_id;\n",
    "#\"\"\").pl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The randomness of what rows are chosen is saved to disk in `random_binary.json`. For each sample #, there is an array with one entry per row, where 1 means the row was chosen and 0 means it was not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(f\"\"\"\n",
    "SELECT sample_id, array_agg(random_binary::TINYINT) as random_binary\n",
    "FROM random_samples\n",
    "GROUP BY sample_id;\n",
    "\"\"\").pl().write_json(f\"{OUTPUT_DIR}/random_binary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query is specified as a prepared statement. We will then execute it once per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (37, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>s_name</th><th>p_partkey</th><th>min(ps_supplycost)</th></tr><tr><td>str</td><td>i64</td><td>decimal[15,2]</td></tr></thead><tbody><tr><td>&quot;Supplier#000000276&quot;</td><td>13275</td><td>764.26</td></tr><tr><td>&quot;Supplier#000000680&quot;</td><td>5679</td><td>19.04</td></tr><tr><td>&quot;Supplier#000000065&quot;</td><td>13275</td><td>624.33</td></tr><tr><td>&quot;Supplier#000000470&quot;</td><td>6213</td><td>601.78</td></tr><tr><td>&quot;Supplier#000000647&quot;</td><td>13120</td><td>115.29</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Supplier#000000044&quot;</td><td>17242</td><td>783.70</td></tr><tr><td>&quot;Supplier#000000563&quot;</td><td>5797</td><td>628.11</td></tr><tr><td>&quot;Supplier#000000477&quot;</td><td>10956</td><td>765.75</td></tr><tr><td>&quot;Supplier#000000812&quot;</td><td>13811</td><td>268.74</td></tr><tr><td>&quot;Supplier#000000812&quot;</td><td>10551</td><td>259.66</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (37, 3)\n",
       "┌────────────────────┬───────────┬────────────────────┐\n",
       "│ s_name             ┆ p_partkey ┆ min(ps_supplycost) │\n",
       "│ ---                ┆ ---       ┆ ---                │\n",
       "│ str                ┆ i64       ┆ decimal[15,2]      │\n",
       "╞════════════════════╪═══════════╪════════════════════╡\n",
       "│ Supplier#000000276 ┆ 13275     ┆ 764.26             │\n",
       "│ Supplier#000000680 ┆ 5679      ┆ 19.04              │\n",
       "│ Supplier#000000065 ┆ 13275     ┆ 624.33             │\n",
       "│ Supplier#000000470 ┆ 6213      ┆ 601.78             │\n",
       "│ Supplier#000000647 ┆ 13120     ┆ 115.29             │\n",
       "│ …                  ┆ …         ┆ …                  │\n",
       "│ Supplier#000000044 ┆ 17242     ┆ 783.70             │\n",
       "│ Supplier#000000563 ┆ 5797      ┆ 628.11             │\n",
       "│ Supplier#000000477 ┆ 10956     ┆ 765.75             │\n",
       "│ Supplier#000000812 ┆ 13811     ┆ 268.74             │\n",
       "│ Supplier#000000812 ┆ 10551     ┆ 259.66             │\n",
       "└────────────────────┴───────────┴────────────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query\n",
    "con.execute(\"\"\"\n",
    "DEALLOCATE PREPARE run_query;\n",
    "\n",
    "PREPARE run_query AS \n",
    "SELECT s_name, p_partkey, min(ps_supplycost)\n",
    "FROM\n",
    "    partsupp,\n",
    "    supplier,\n",
    "    part,\n",
    "    nation,\n",
    "    region\n",
    "JOIN random_samples AS rs ON rs.row_id = supplier.rowid\n",
    "WHERE\n",
    "    p_partkey = ps_partkey\n",
    "    AND p_size = 15\n",
    "    AND p_type LIKE '%BRASS'\n",
    "    AND s_suppkey = ps_suppkey\n",
    "    AND s_nationkey = n_nationkey\n",
    "    AND n_regionkey = r_regionkey\n",
    "    AND r_name = 'EUROPE'\n",
    "    AND rs.random_binary = TRUE\n",
    "    AND rs.sample_id = $sample\n",
    "GROUP BY s_name, p_partkey;\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"EXECUTE run_query(sample := {0});\").pl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now generate the query result for each sample. The query output of each sample is saved to disk in multiple formats:\n",
    "- `csv` contains one file per sample, with the table written in CSV format. This does not preserve data type information.\n",
    "- `parquet` contains one file per sample, with the table written in Parquet format. This preserves data type information as apache arrow converted types.\n",
    "- `dfs.pkl` contains the python list of polars dataframes in a binary format. This could be used to resume the notebook with the exact same previously-used randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all the queries\n",
    "dfs: List[pl.DataFrame] = []\n",
    "for s in range(SAMPLES):\n",
    "    dfs.append(con.execute(f\"EXECUTE run_query(sample := {s});\").pl())\n",
    "\n",
    "# Save the results to disk\n",
    "os.makedirs(f\"{OUTPUT_DIR}/csv\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/parquet\", exist_ok=True)\n",
    "for i, df in enumerate(dfs):\n",
    "    df.write_csv(f\"{OUTPUT_DIR}/csv/sample_{i}.csv\")\n",
    "    df.write_parquet(f\"{OUTPUT_DIR}/parquet/sample_{i}.parquet\")\n",
    "with open(f\"{OUTPUT_DIR}/dfs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dfs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples have been generated and stored in `outputs/{OUTPUT_DIR}/csv/sample_{i}.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s_name', 'p_partkey', 'min(ps_supplycost)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output schema: Schema([('s_name', String), ('p_partkey', Int64), ('min(ps_supplycost)', Decimal(precision=15, scale=2))])\n",
      "Output shape: (37, 3)\n"
     ]
    }
   ],
   "source": [
    "INDEX_COLS = ['s_name', 'p_partkey']\n",
    "OUTPUT_COLS = ['s_name', 'p_partkey', 'min(ps_supplycost)']\n",
    "OUTPUT_SCHEMA = dfs[0].select(OUTPUT_COLS).collect_schema()\n",
    "OUTPUT_SHAPE = dfs[0].select(OUTPUT_COLS).to_numpy().shape\n",
    "with open(f\"{OUTPUT_DIR}/schema.txt\", \"w\") as f:\n",
    "    f.write(str(OUTPUT_SCHEMA))\n",
    "print(f\"Output schema: {OUTPUT_SCHEMA}\")\n",
    "print(f\"Output shape: {OUTPUT_SHAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (37, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>s_name</th><th>p_partkey</th><th>min(ps_supplycost)</th></tr><tr><td>str</td><td>i64</td><td>decimal[15,2]</td></tr></thead><tbody><tr><td>&quot;Supplier#000000276&quot;</td><td>13275</td><td>764.26</td></tr><tr><td>&quot;Supplier#000000680&quot;</td><td>5679</td><td>19.04</td></tr><tr><td>&quot;Supplier#000000065&quot;</td><td>13275</td><td>624.33</td></tr><tr><td>&quot;Supplier#000000470&quot;</td><td>6213</td><td>601.78</td></tr><tr><td>&quot;Supplier#000000647&quot;</td><td>13120</td><td>115.29</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Supplier#000000044&quot;</td><td>17242</td><td>783.70</td></tr><tr><td>&quot;Supplier#000000563&quot;</td><td>5797</td><td>628.11</td></tr><tr><td>&quot;Supplier#000000477&quot;</td><td>10956</td><td>765.75</td></tr><tr><td>&quot;Supplier#000000812&quot;</td><td>13811</td><td>268.74</td></tr><tr><td>&quot;Supplier#000000812&quot;</td><td>10551</td><td>259.66</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (37, 3)\n",
       "┌────────────────────┬───────────┬────────────────────┐\n",
       "│ s_name             ┆ p_partkey ┆ min(ps_supplycost) │\n",
       "│ ---                ┆ ---       ┆ ---                │\n",
       "│ str                ┆ i64       ┆ decimal[15,2]      │\n",
       "╞════════════════════╪═══════════╪════════════════════╡\n",
       "│ Supplier#000000276 ┆ 13275     ┆ 764.26             │\n",
       "│ Supplier#000000680 ┆ 5679      ┆ 19.04              │\n",
       "│ Supplier#000000065 ┆ 13275     ┆ 624.33             │\n",
       "│ Supplier#000000470 ┆ 6213      ┆ 601.78             │\n",
       "│ Supplier#000000647 ┆ 13120     ┆ 115.29             │\n",
       "│ …                  ┆ …         ┆ …                  │\n",
       "│ Supplier#000000044 ┆ 17242     ┆ 783.70             │\n",
       "│ Supplier#000000563 ┆ 5797      ┆ 628.11             │\n",
       "│ Supplier#000000477 ┆ 10956     ┆ 765.75             │\n",
       "│ Supplier#000000812 ┆ 13811     ┆ 268.74             │\n",
       "│ Supplier#000000812 ┆ 10551     ┆ 259.66             │\n",
       "└────────────────────┴───────────┴────────────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].select(OUTPUT_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpyify(df: pl.DataFrame) -> np.ndarray:\n",
    "    return df.select(OUTPUT_COLS).to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (37, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>s_name</th><th>p_partkey</th><th>min(ps_supplycost)</th></tr><tr><td>str</td><td>i64</td><td>decimal[15,2]</td></tr></thead><tbody><tr><td>&quot;Supplier#000000276&quot;</td><td>13275</td><td>764.26</td></tr><tr><td>&quot;Supplier#000000680&quot;</td><td>5679</td><td>19.04</td></tr><tr><td>&quot;Supplier#000000065&quot;</td><td>13275</td><td>624.33</td></tr><tr><td>&quot;Supplier#000000470&quot;</td><td>6213</td><td>601.78</td></tr><tr><td>&quot;Supplier#000000647&quot;</td><td>13120</td><td>115.29</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Supplier#000000044&quot;</td><td>17242</td><td>783.70</td></tr><tr><td>&quot;Supplier#000000563&quot;</td><td>5797</td><td>628.11</td></tr><tr><td>&quot;Supplier#000000477&quot;</td><td>10956</td><td>765.75</td></tr><tr><td>&quot;Supplier#000000812&quot;</td><td>13811</td><td>268.74</td></tr><tr><td>&quot;Supplier#000000812&quot;</td><td>10551</td><td>259.66</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (37, 3)\n",
       "┌────────────────────┬───────────┬────────────────────┐\n",
       "│ s_name             ┆ p_partkey ┆ min(ps_supplycost) │\n",
       "│ ---                ┆ ---       ┆ ---                │\n",
       "│ str                ┆ i64       ┆ decimal[15,2]      │\n",
       "╞════════════════════╪═══════════╪════════════════════╡\n",
       "│ Supplier#000000276 ┆ 13275     ┆ 764.26             │\n",
       "│ Supplier#000000680 ┆ 5679      ┆ 19.04              │\n",
       "│ Supplier#000000065 ┆ 13275     ┆ 624.33             │\n",
       "│ Supplier#000000470 ┆ 6213      ┆ 601.78             │\n",
       "│ Supplier#000000647 ┆ 13120     ┆ 115.29             │\n",
       "│ …                  ┆ …         ┆ …                  │\n",
       "│ Supplier#000000044 ┆ 17242     ┆ 783.70             │\n",
       "│ Supplier#000000563 ┆ 5797      ┆ 628.11             │\n",
       "│ Supplier#000000477 ┆ 10956     ┆ 765.75             │\n",
       "│ Supplier#000000812 ┆ 13811     ┆ 268.74             │\n",
       "│ Supplier#000000812 ┆ 10551     ┆ 259.66             │\n",
       "└────────────────────┴───────────┴────────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tablify(arr: np.ndarray) -> pl.DataFrame:\n",
    "    global OUTPUT_SHAPE, OUTPUT_SCHEMA\n",
    "    return dfs[0].update( # put values back into the original dataframe\n",
    "        pl.DataFrame(\n",
    "            arr.reshape(OUTPUT_SHAPE), # reshape to the original shape\n",
    "            schema=OUTPUT_SCHEMA # coerce numpy array to the correct schema\n",
    "        ) # index cols will be left unchanged (not updated b/c we only update output_cols)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples in numpy format are saved to disk in a variety of ways, all of which contain the same data:\n",
    "- `npy` contains arrays saved in the Numpy format. See https://numpy.org/doc/stable/reference/generated/numpy.lib.format.html\n",
    "- `npcsv` contains numpy arrays saved in the CSV format. These are 1D arrays of whatever data type (probably float) is in the table.\n",
    "- `nparr.npz` contains all the numpy arrays saved in the Numpy format for saving multiple arrays in one file. See https://numpy.org/doc/stable/reference/generated/numpy.savez.html\n",
    "- `nparr.pkl` contains the python list of numpy arrays in a binary format, if you don't want to use the numpy format for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrames to numpy arrays\n",
    "nparr = [numpyify(df) for df in dfs]\n",
    "\n",
    "# Save the numpy arrays to disk\n",
    "os.makedirs(f\"{OUTPUT_DIR}/npy\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/npcsv\", exist_ok=True)\n",
    "for i, arr in enumerate(nparr):\n",
    "    np.save(f\"{OUTPUT_DIR}/npy/arr_{i}.npy\", arr)\n",
    "for i, arr in enumerate(nparr):\n",
    "    with open(f\"{OUTPUT_DIR}/npcsv/arr_{i}.csv\", \"w\", newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(arr)\n",
    "np.savez(f\"{OUTPUT_DIR}/nparr.npz\", *nparr)\n",
    "with open(f\"{OUTPUT_DIR}/nparr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(nparr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how to load the `npz` file into an array of 'samples' where the samples are each a 1d numpy array.\n",
    "```python\n",
    "test = np.load(f\"{OUTPUT_DIR}/nparr.npz\")\n",
    "npsamples = [test[f'arr_{i}'] for i in range(SAMPLES)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.load(f\"{OUTPUT_DIR}/nparr.npz\", allow_pickle=True)\n",
    "npsamples = [test[f'arr_{i}'] for i in range(SAMPLES)]\n",
    "npsamples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michael/projects/dpdb/pacdb/outputs/pac-duckdb-q2-inner.zip'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip the OUTPUT_DIR\n",
    "import shutil\n",
    "shutil.make_archive(OUTPUT_DIR, 'zip', OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
