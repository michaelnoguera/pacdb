{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e19279",
   "metadata": {
    "papermill": {
     "duration": 0.002692,
     "end_time": "2025-05-01T08:53:47.727921",
     "exception": false,
     "start_time": "2025-05-01T08:53:47.725229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DuckDB Notebook\n",
    "\n",
    "This notebook generates a bunch of raw outputs, without applying PAC, to be consumed by a second stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b667e",
   "metadata": {
    "papermill": {
     "duration": 0.001623,
     "end_time": "2025-05-01T08:53:47.731663",
     "exception": false,
     "start_time": "2025-05-01T08:53:47.730040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```\n",
    " group by              output cols                        \n",
    " key cols ┌────────┬────────┬────────┬────────┐           \n",
    "        │ │   A    │   B    │   C    │   D    │           \n",
    "      ┌─▼─┼────────┼────────┼────────┼────────┤           \n",
    "      │ 1 │   2    │        │        │        │           \n",
    "      ├───┼───|────┼────────┼────────┼────────┤           \n",
    "      │ 2 │   │    │        │        │        │           \n",
    "      ├───┼───┼────┼────────┼────────┼────────┤           \n",
    "      │ 3 │   │    │        │        │        │           \n",
    "      └───┴───┼────┴────────┴────────┴────────┘           \n",
    "              ▼                 A_1.json                  \n",
    "       Sample 0:   A1=2        ┌─────────────────────────┐\n",
    "       Sample 1:   A1=4  ───▶  │{                        │\n",
    "             ...               │    col: A               │\n",
    "       Sample 999: A1=3        │    row: 1               │\n",
    "                               │    value: [2, 4, ... 3] │\n",
    "                               │}                        │\n",
    "                               └─────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c92cd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T08:53:47.735668Z",
     "iopub.status.busy": "2025-05-01T08:53:47.735415Z",
     "iopub.status.idle": "2025-05-01T08:53:47.800181Z",
     "shell.execute_reply": "2025-05-01T08:53:47.799847Z"
    },
    "papermill": {
     "duration": 0.067862,
     "end_time": "2025-05-01T08:53:47.801114",
     "exception": false,
     "start_time": "2025-05-01T08:53:47.733252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "import duckdb\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c94edc17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T08:53:47.804256Z",
     "iopub.status.busy": "2025-05-01T08:53:47.804150Z",
     "iopub.status.idle": "2025-05-01T08:53:47.806733Z",
     "shell.execute_reply": "2025-05-01T08:53:47.806519Z"
    },
    "papermill": {
     "duration": 0.004815,
     "end_time": "2025-05-01T08:53:47.807427",
     "exception": false,
     "start_time": "2025-05-01T08:53:47.802612",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "EXPERIMENT = \"pac-duckdb-q1\"\n",
    "OUTPUT_DIR = f\"./outputs/{EXPERIMENT}-step1\"\n",
    "SAMPLES = 1024\n",
    "\n",
    "SAMPLE_STEP = f\"\"\"\n",
    "DROP TABLE IF EXISTS random_samples;\n",
    "\n",
    "CREATE TABLE random_samples AS\n",
    "WITH sample_numbers AS MATERIALIZED (\n",
    "    SELECT range AS sample_id FROM range({SAMPLES//2})\n",
    "), random_values AS MATERIALIZED (\n",
    "    SELECT \n",
    "        sample_numbers.sample_id,\n",
    "        customer.rowid AS row_id,\n",
    "        (RANDOM() > 0.5)::BOOLEAN AS random_binary\n",
    "    FROM sample_numbers\n",
    "    JOIN customer ON TRUE  -- Cross join to duplicate rows for each sample\n",
    ")\n",
    "SELECT\n",
    "    sample_id,\n",
    "    row_id,\n",
    "    random_binary\n",
    "FROM random_values\n",
    "UNION ALL\n",
    "SELECT -- select the complementary samples too\n",
    "    ({SAMPLES//2}) + sample_id,\n",
    "    row_id,\n",
    "    NOT random_binary  -- Inverse the random_binary to get the complementary sample\n",
    "FROM random_values\n",
    "ORDER BY sample_id, row_id;\n",
    "\"\"\"\n",
    "\n",
    "PREPARE_STEP = \"\"\"\n",
    "DEALLOCATE PREPARE run_query;\n",
    "\n",
    "PREPARE run_query AS \n",
    "SELECT\n",
    "    l_returnflag,\n",
    "    l_linestatus,\n",
    "    2*sum(l_quantity) AS sum_qty,\n",
    "    2*sum(l_extendedprice) AS sum_base_price,\n",
    "    2*sum(l_extendedprice * (1 - l_discount)) AS sum_disc_price,\n",
    "    2*sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) AS sum_charge,\n",
    "    avg(l_quantity) AS avg_qty,\n",
    "    avg(l_extendedprice) AS avg_price,\n",
    "    avg(l_discount) AS avg_disc,\n",
    "    2*count(*) AS count_order\n",
    "FROM\n",
    "    lineitem\n",
    "JOIN orders ON lineitem.l_orderkey = orders.o_orderkey\n",
    "JOIN customer ON orders.o_custkey = customer.c_custkey\n",
    "JOIN random_samples AS rs\n",
    "    ON rs.row_id = customer.rowid\n",
    "WHERE\n",
    "    l_shipdate <= CAST('1998-09-02' AS date)\n",
    "    AND rs.random_binary = TRUE\n",
    "    AND rs.sample_id = $sample\n",
    "GROUP BY\n",
    "    l_returnflag,\n",
    "    l_linestatus\n",
    "ORDER BY\n",
    "    l_returnflag,\n",
    "    l_linestatus;\n",
    "\"\"\"\n",
    "\n",
    "INDEX_COLS = ['l_returnflag', 'l_linestatus']\n",
    "OUTPUT_COLS = ['sum_qty', 'sum_base_price', 'sum_disc_price', 'sum_charge', 'avg_qty', 'avg_price', 'avg_disc', 'count_order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e538fc7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T08:53:47.810303Z",
     "iopub.status.busy": "2025-05-01T08:53:47.810207Z",
     "iopub.status.idle": "2025-05-01T08:53:47.812184Z",
     "shell.execute_reply": "2025-05-01T08:53:47.811983Z"
    },
    "papermill": {
     "duration": 0.004069,
     "end_time": "2025-05-01T08:53:47.812801",
     "exception": false,
     "start_time": "2025-05-01T08:53:47.808732",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "EXPERIMENT = \"ap-duckdb-q9-customer\"\n",
    "OUTPUT_DIR = \"./outputs/ap-duckdb-q9-customer-step1\"\n",
    "SAMPLES = 1024\n",
    "SAMPLE_STEP = \"DROP TABLE IF EXISTS random_samples;\\n\\nCREATE TABLE random_samples AS\\nWITH sample_numbers AS MATERIALIZED (\\n    SELECT range AS sample_id FROM range(1024 // 2)\\n), random_values AS MATERIALIZED (\\n    SELECT \\n        sample_numbers.sample_id,\\n        customer.rowid AS row_id,\\n        (RANDOM() > 0.5)::BOOLEAN AS random_binary\\n    FROM sample_numbers\\n    JOIN customer ON TRUE  -- Cross join to duplicate rows for each sample\\n)\\nSELECT\\n    sample_id,\\n    row_id,\\n    random_binary\\nFROM random_values\\nUNION ALL\\nSELECT -- select the complementary samples too\\n    (1024 // 2) + sample_id,\\n    row_id,\\n    NOT random_binary  -- Inverse the random_binary to get the complementary sample\\nFROM random_values\\nORDER BY sample_id, row_id;\"\n",
    "PREPARE_STEP = \"DEALLOCATE PREPARE run_query;\\n\\nPREPARE run_query AS \\nSELECT\\n    nation,\\n    o_year,\\n    sum(amount) AS sum_profit\\nFROM (\\n    SELECT\\n        n_name AS nation,\\n        extract(year FROM o_orderdate) AS o_year,\\n        l_extendedprice * (1 - l_discount) - ps_supplycost * l_quantity AS amount\\n    FROM\\n        part,\\n        supplier,\\n        lineitem,\\n        partsupp,\\n        orders,\\n        nation,\\n        customer,\\n        random_samples AS rs\\n    WHERE\\n        rs.row_id = customer.rowid\\n        AND rs.random_binary = TRUE\\n        AND rs.sample_id = $sample\\n        AND o_custkey = c_custkey\\n        AND s_suppkey = l_suppkey\\n        AND ps_suppkey = l_suppkey\\n        AND ps_partkey = l_partkey\\n        AND p_partkey = l_partkey\\n        AND o_orderkey = l_orderkey\\n        AND s_nationkey = n_nationkey\\n        AND p_name LIKE '%green%') AS profit\\nGROUP BY\\n    nation,\\n    o_year\\nORDER BY\\n    nation,\\n    o_year DESC;\"\n",
    "INDEX_COLS = [\"nation\", \"o_year\"]\n",
    "OUTPUT_COLS = [\"sum_profit\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b798f7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T08:53:47.815743Z",
     "iopub.status.busy": "2025-05-01T08:53:47.815651Z",
     "iopub.status.idle": "2025-05-01T08:53:47.817252Z",
     "shell.execute_reply": "2025-05-01T08:53:47.817008Z"
    },
    "papermill": {
     "duration": 0.003751,
     "end_time": "2025-05-01T08:53:47.817876",
     "exception": false,
     "start_time": "2025-05-01T08:53:47.814125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e38b14c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T08:53:47.820914Z",
     "iopub.status.busy": "2025-05-01T08:53:47.820821Z",
     "iopub.status.idle": "2025-05-01T08:53:48.135245Z",
     "shell.execute_reply": "2025-05-01T08:53:48.134976Z"
    },
    "papermill": {
     "duration": 0.316774,
     "end_time": "2025-05-01T08:53:48.136081",
     "exception": false,
     "start_time": "2025-05-01T08:53:47.819307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# duckdb load data/tpch/tpch.duckdb into the temporary in-memory database\n",
    "con = duckdb.connect(database=':memory:')\n",
    "tables = [\"customer\", \"lineitem\", \"nation\", \"orders\", \"part\", \"partsupp\", \"region\", \"supplier\"]\n",
    "for t in tables:\n",
    "    con.execute(f\"CREATE TABLE {t} AS SELECT * FROM 'data/tpch/{t}.parquet'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df550192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T08:53:48.139594Z",
     "iopub.status.busy": "2025-05-01T08:53:48.139483Z",
     "iopub.status.idle": "2025-05-01T08:53:49.156916Z",
     "shell.execute_reply": "2025-05-01T08:53:49.156483Z"
    },
    "papermill": {
     "duration": 1.020002,
     "end_time": "2025-05-01T08:53:49.157791",
     "exception": false,
     "start_time": "2025-05-01T08:53:48.137789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct the table of random samples\n",
    "# to use, join it with the lineitem table (for specific sample # s) and filter to just the\n",
    "# rows where random_binary = 1.0\n",
    "# This will give us a 50% sample of the lineitem table for each sample # s\n",
    "\n",
    "assert SAMPLES % 2 == 0, \"SAMPLES must be even to create complementary samples.\"\n",
    "\n",
    "random_samples = con.execute(SAMPLE_STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c6c77",
   "metadata": {
    "papermill": {
     "duration": 0.001252,
     "end_time": "2025-05-01T08:53:49.160687",
     "exception": false,
     "start_time": "2025-05-01T08:53:49.159435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The randomness of what rows are chosen is saved to disk in `random_binary.json`. For each sample #, there is an array with one entry per row, where 1 means the row was chosen and 0 means it was not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "396d89af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T08:53:49.163541Z",
     "iopub.status.busy": "2025-05-01T08:53:49.163445Z",
     "iopub.status.idle": "2025-05-01T08:53:49.483199Z",
     "shell.execute_reply": "2025-05-01T08:53:49.482432Z"
    },
    "papermill": {
     "duration": 0.322303,
     "end_time": "2025-05-01T08:53:49.484204",
     "exception": false,
     "start_time": "2025-05-01T08:53:49.161901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "SELECT sample_id, array_agg(random_binary::TINYINT) as random_binary\n",
    "FROM random_samples\n",
    "GROUP BY sample_id;\n",
    "\"\"\").pl().write_json(f\"{OUTPUT_DIR}/random_binary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b456758",
   "metadata": {
    "papermill": {
     "duration": 0.001338,
     "end_time": "2025-05-01T08:53:49.487248",
     "exception": false,
     "start_time": "2025-05-01T08:53:49.485910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Query is specified as a prepared statement. We will then execute it once per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11292384",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T08:53:49.490463Z",
     "iopub.status.busy": "2025-05-01T08:53:49.490208Z",
     "iopub.status.idle": "2025-05-01T08:53:49.609481Z",
     "shell.execute_reply": "2025-05-01T08:53:49.609129Z"
    },
    "papermill": {
     "duration": 0.121684,
     "end_time": "2025-05-01T08:53:49.610232",
     "exception": false,
     "start_time": "2025-05-01T08:53:49.488548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (175, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>nation</th><th>o_year</th><th>sum_profit</th></tr><tr><td>str</td><td>i64</td><td>decimal[38,4]</td></tr></thead><tbody><tr><td>&quot;ALGERIA&quot;</td><td>1998</td><td>1209342.8492</td></tr><tr><td>&quot;ALGERIA&quot;</td><td>1997</td><td>1935176.3374</td></tr><tr><td>&quot;ALGERIA&quot;</td><td>1996</td><td>2234737.3550</td></tr><tr><td>&quot;ALGERIA&quot;</td><td>1995</td><td>2146191.3543</td></tr><tr><td>&quot;ALGERIA&quot;</td><td>1994</td><td>1827685.4208</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;VIETNAM&quot;</td><td>1996</td><td>1917007.7274</td></tr><tr><td>&quot;VIETNAM&quot;</td><td>1995</td><td>1618999.5005</td></tr><tr><td>&quot;VIETNAM&quot;</td><td>1994</td><td>2156527.5295</td></tr><tr><td>&quot;VIETNAM&quot;</td><td>1993</td><td>1222217.6648</td></tr><tr><td>&quot;VIETNAM&quot;</td><td>1992</td><td>2156855.0291</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (175, 3)\n",
       "┌─────────┬────────┬───────────────┐\n",
       "│ nation  ┆ o_year ┆ sum_profit    │\n",
       "│ ---     ┆ ---    ┆ ---           │\n",
       "│ str     ┆ i64    ┆ decimal[38,4] │\n",
       "╞═════════╪════════╪═══════════════╡\n",
       "│ ALGERIA ┆ 1998   ┆ 1209342.8492  │\n",
       "│ ALGERIA ┆ 1997   ┆ 1935176.3374  │\n",
       "│ ALGERIA ┆ 1996   ┆ 2234737.3550  │\n",
       "│ ALGERIA ┆ 1995   ┆ 2146191.3543  │\n",
       "│ ALGERIA ┆ 1994   ┆ 1827685.4208  │\n",
       "│ …       ┆ …      ┆ …             │\n",
       "│ VIETNAM ┆ 1996   ┆ 1917007.7274  │\n",
       "│ VIETNAM ┆ 1995   ┆ 1618999.5005  │\n",
       "│ VIETNAM ┆ 1994   ┆ 2156527.5295  │\n",
       "│ VIETNAM ┆ 1993   ┆ 1222217.6648  │\n",
       "│ VIETNAM ┆ 1992   ┆ 2156855.0291  │\n",
       "└─────────┴────────┴───────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query\n",
    "con.execute(PREPARE_STEP)\n",
    "\n",
    "# Run query to see output\n",
    "dfs0 = con.execute(f\"EXECUTE run_query(sample := {0});\").pl()\n",
    "\n",
    "# Save csv copies of the first 5 samples\n",
    "os.makedirs(f\"{OUTPUT_DIR}/csv\", exist_ok=True)\n",
    "for s in range(5):\n",
    "    con.execute(f\"EXECUTE run_query(sample := {s});\").pl().write_csv(f\"{OUTPUT_DIR}/csv/sample_{s}.csv\")\n",
    "\n",
    "dfs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b461f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T08:53:49.613651Z",
     "iopub.status.busy": "2025-05-01T08:53:49.613539Z",
     "iopub.status.idle": "2025-05-01T08:54:04.957888Z",
     "shell.execute_reply": "2025-05-01T08:54:04.957546Z"
    },
    "papermill": {
     "duration": 15.347787,
     "end_time": "2025-05-01T08:54:04.959654",
     "exception": false,
     "start_time": "2025-05-01T08:53:49.611867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (179_200, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sample</th><th>nation</th><th>o_year</th><th>sum_profit</th></tr><tr><td>i32</td><td>str</td><td>i64</td><td>decimal[38,4]</td></tr></thead><tbody><tr><td>0</td><td>&quot;ALGERIA&quot;</td><td>1998</td><td>1209342.8492</td></tr><tr><td>0</td><td>&quot;ALGERIA&quot;</td><td>1997</td><td>1935176.3374</td></tr><tr><td>0</td><td>&quot;ALGERIA&quot;</td><td>1996</td><td>2234737.3550</td></tr><tr><td>0</td><td>&quot;ALGERIA&quot;</td><td>1995</td><td>2146191.3543</td></tr><tr><td>0</td><td>&quot;ALGERIA&quot;</td><td>1994</td><td>1827685.4208</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1023</td><td>&quot;VIETNAM&quot;</td><td>1996</td><td>1910016.2699</td></tr><tr><td>1023</td><td>&quot;VIETNAM&quot;</td><td>1995</td><td>1721376.8757</td></tr><tr><td>1023</td><td>&quot;VIETNAM&quot;</td><td>1994</td><td>2105542.6955</td></tr><tr><td>1023</td><td>&quot;VIETNAM&quot;</td><td>1993</td><td>1161359.5221</td></tr><tr><td>1023</td><td>&quot;VIETNAM&quot;</td><td>1992</td><td>2267197.6648</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (179_200, 4)\n",
       "┌────────┬─────────┬────────┬───────────────┐\n",
       "│ sample ┆ nation  ┆ o_year ┆ sum_profit    │\n",
       "│ ---    ┆ ---     ┆ ---    ┆ ---           │\n",
       "│ i32    ┆ str     ┆ i64    ┆ decimal[38,4] │\n",
       "╞════════╪═════════╪════════╪═══════════════╡\n",
       "│ 0      ┆ ALGERIA ┆ 1998   ┆ 1209342.8492  │\n",
       "│ 0      ┆ ALGERIA ┆ 1997   ┆ 1935176.3374  │\n",
       "│ 0      ┆ ALGERIA ┆ 1996   ┆ 2234737.3550  │\n",
       "│ 0      ┆ ALGERIA ┆ 1995   ┆ 2146191.3543  │\n",
       "│ 0      ┆ ALGERIA ┆ 1994   ┆ 1827685.4208  │\n",
       "│ …      ┆ …       ┆ …      ┆ …             │\n",
       "│ 1023   ┆ VIETNAM ┆ 1996   ┆ 1910016.2699  │\n",
       "│ 1023   ┆ VIETNAM ┆ 1995   ┆ 1721376.8757  │\n",
       "│ 1023   ┆ VIETNAM ┆ 1994   ┆ 2105542.6955  │\n",
       "│ 1023   ┆ VIETNAM ┆ 1993   ┆ 1161359.5221  │\n",
       "│ 1023   ┆ VIETNAM ┆ 1992   ┆ 2267197.6648  │\n",
       "└────────┴─────────┴────────┴───────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the query for each sample, but accumulate in a pl.DataFrame instead of a list\n",
    "dfsdf: pl.DataFrame = pl.concat(\n",
    "    con.execute(f\"EXECUTE run_query(sample := {s});\").pl().insert_column(0, pl.lit(s).alias(\"sample\"))\n",
    "    for s in range(SAMPLES)\n",
    ")\n",
    "dfsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5d6ddbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T08:54:04.964065Z",
     "iopub.status.busy": "2025-05-01T08:54:04.963933Z",
     "iopub.status.idle": "2025-05-01T08:54:04.966202Z",
     "shell.execute_reply": "2025-05-01T08:54:04.965992Z"
    },
    "papermill": {
     "duration": 0.004832,
     "end_time": "2025-05-01T08:54:04.966803",
     "exception": false,
     "start_time": "2025-05-01T08:54:04.961971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define which columns are the group-by keys (INDEX_COLS) and which are the output columns (OUTPUT_COLS)\n",
    "# - moved to parameters cell at top of notebook\n",
    "\n",
    "# Save these to disk for later use\n",
    "with open(f\"{OUTPUT_DIR}/INDEX_COLS.pkl\", 'wb') as f:\n",
    "    pickle.dump(INDEX_COLS, f)\n",
    "with open(f\"{OUTPUT_DIR}/OUTPUT_COLS.pkl\", 'wb') as f:\n",
    "    pickle.dump(OUTPUT_COLS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dccd3205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T08:54:04.970216Z",
     "iopub.status.busy": "2025-05-01T08:54:04.970124Z",
     "iopub.status.idle": "2025-05-01T08:54:04.996855Z",
     "shell.execute_reply": "2025-05-01T08:54:04.996511Z"
    },
    "papermill": {
     "duration": 0.030927,
     "end_time": "2025-05-01T08:54:04.999298",
     "exception": false,
     "start_time": "2025-05-01T08:54:04.968371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (175, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>nation</th><th>o_year</th><th>sum_profit</th></tr><tr><td>str</td><td>i64</td><td>list[decimal[38,4]]</td></tr></thead><tbody><tr><td>&quot;ALGERIA&quot;</td><td>1998</td><td>[1209342.8492, 1243573.7710, … 1255229.5045]</td></tr><tr><td>&quot;ALGERIA&quot;</td><td>1997</td><td>[1935176.3374, 2157308.1409, … 1987308.7639]</td></tr><tr><td>&quot;ALGERIA&quot;</td><td>1996</td><td>[2234737.3550, 1785117.0985, … 2236631.4048]</td></tr><tr><td>&quot;ALGERIA&quot;</td><td>1995</td><td>[2146191.3543, 2342536.9983, … 2319283.1205]</td></tr><tr><td>&quot;ALGERIA&quot;</td><td>1994</td><td>[1827685.4208, 1614319.7053, … 1978220.8626]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;VIETNAM&quot;</td><td>1996</td><td>[1917007.7274, 2355737.9181, … 1910016.2699]</td></tr><tr><td>&quot;VIETNAM&quot;</td><td>1995</td><td>[1618999.5005, 1886185.0270, … 1721376.8757]</td></tr><tr><td>&quot;VIETNAM&quot;</td><td>1994</td><td>[2156527.5295, 2341943.6896, … 2105542.6955]</td></tr><tr><td>&quot;VIETNAM&quot;</td><td>1993</td><td>[1222217.6648, 1304442.5760, … 1161359.5221]</td></tr><tr><td>&quot;VIETNAM&quot;</td><td>1992</td><td>[2156855.0291, 2158282.8281, … 2267197.6648]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (175, 3)\n",
       "┌─────────┬────────┬─────────────────────────────────┐\n",
       "│ nation  ┆ o_year ┆ sum_profit                      │\n",
       "│ ---     ┆ ---    ┆ ---                             │\n",
       "│ str     ┆ i64    ┆ list[decimal[38,4]]             │\n",
       "╞═════════╪════════╪═════════════════════════════════╡\n",
       "│ ALGERIA ┆ 1998   ┆ [1209342.8492, 1243573.7710, …… │\n",
       "│ ALGERIA ┆ 1997   ┆ [1935176.3374, 2157308.1409, …… │\n",
       "│ ALGERIA ┆ 1996   ┆ [2234737.3550, 1785117.0985, …… │\n",
       "│ ALGERIA ┆ 1995   ┆ [2146191.3543, 2342536.9983, …… │\n",
       "│ ALGERIA ┆ 1994   ┆ [1827685.4208, 1614319.7053, …… │\n",
       "│ …       ┆ …      ┆ …                               │\n",
       "│ VIETNAM ┆ 1996   ┆ [1917007.7274, 2355737.9181, …… │\n",
       "│ VIETNAM ┆ 1995   ┆ [1618999.5005, 1886185.0270, …… │\n",
       "│ VIETNAM ┆ 1994   ┆ [2156527.5295, 2341943.6896, …… │\n",
       "│ VIETNAM ┆ 1993   ┆ [1222217.6648, 1304442.5760, …… │\n",
       "│ VIETNAM ┆ 1992   ┆ [2156855.0291, 2158282.8281, …… │\n",
       "└─────────┴────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all the samples into one table, grouped-by the group-by keys. Each cell contains an n <= # of samples length array of values.\n",
    "listdf = dfsdf.drop(\"sample\").group_by(INDEX_COLS or pl.lit(0).alias(\"\"), maintain_order=True).all()\n",
    "listdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dce3acd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T08:54:05.003700Z",
     "iopub.status.busy": "2025-05-01T08:54:05.003571Z",
     "iopub.status.idle": "2025-05-01T08:54:05.008817Z",
     "shell.execute_reply": "2025-05-01T08:54:05.008586Z"
    },
    "papermill": {
     "duration": 0.008357,
     "end_time": "2025-05-01T08:54:05.009488",
     "exception": false,
     "start_time": "2025-05-01T08:54:05.001131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nation': 'ALGERIA', 'o_year': 1998},\n",
       " {'nation': 'ALGERIA', 'o_year': 1997},\n",
       " {'nation': 'ALGERIA', 'o_year': 1996},\n",
       " {'nation': 'ALGERIA', 'o_year': 1995},\n",
       " {'nation': 'ALGERIA', 'o_year': 1994},\n",
       " {'nation': 'ALGERIA', 'o_year': 1993},\n",
       " {'nation': 'ALGERIA', 'o_year': 1992},\n",
       " {'nation': 'ARGENTINA', 'o_year': 1998},\n",
       " {'nation': 'ARGENTINA', 'o_year': 1997},\n",
       " {'nation': 'ARGENTINA', 'o_year': 1996},\n",
       " {'nation': 'ARGENTINA', 'o_year': 1995},\n",
       " {'nation': 'ARGENTINA', 'o_year': 1994},\n",
       " {'nation': 'ARGENTINA', 'o_year': 1993},\n",
       " {'nation': 'ARGENTINA', 'o_year': 1992},\n",
       " {'nation': 'BRAZIL', 'o_year': 1998},\n",
       " {'nation': 'BRAZIL', 'o_year': 1997},\n",
       " {'nation': 'BRAZIL', 'o_year': 1996},\n",
       " {'nation': 'BRAZIL', 'o_year': 1995},\n",
       " {'nation': 'BRAZIL', 'o_year': 1994},\n",
       " {'nation': 'BRAZIL', 'o_year': 1993},\n",
       " {'nation': 'BRAZIL', 'o_year': 1992},\n",
       " {'nation': 'CANADA', 'o_year': 1998},\n",
       " {'nation': 'CANADA', 'o_year': 1997},\n",
       " {'nation': 'CANADA', 'o_year': 1996},\n",
       " {'nation': 'CANADA', 'o_year': 1995},\n",
       " {'nation': 'CANADA', 'o_year': 1994},\n",
       " {'nation': 'CANADA', 'o_year': 1993},\n",
       " {'nation': 'CANADA', 'o_year': 1992},\n",
       " {'nation': 'CHINA', 'o_year': 1998},\n",
       " {'nation': 'CHINA', 'o_year': 1997},\n",
       " {'nation': 'CHINA', 'o_year': 1996},\n",
       " {'nation': 'CHINA', 'o_year': 1995},\n",
       " {'nation': 'CHINA', 'o_year': 1994},\n",
       " {'nation': 'CHINA', 'o_year': 1993},\n",
       " {'nation': 'CHINA', 'o_year': 1992},\n",
       " {'nation': 'EGYPT', 'o_year': 1998},\n",
       " {'nation': 'EGYPT', 'o_year': 1997},\n",
       " {'nation': 'EGYPT', 'o_year': 1996},\n",
       " {'nation': 'EGYPT', 'o_year': 1995},\n",
       " {'nation': 'EGYPT', 'o_year': 1994},\n",
       " {'nation': 'EGYPT', 'o_year': 1993},\n",
       " {'nation': 'EGYPT', 'o_year': 1992},\n",
       " {'nation': 'ETHIOPIA', 'o_year': 1998},\n",
       " {'nation': 'ETHIOPIA', 'o_year': 1997},\n",
       " {'nation': 'ETHIOPIA', 'o_year': 1996},\n",
       " {'nation': 'ETHIOPIA', 'o_year': 1995},\n",
       " {'nation': 'ETHIOPIA', 'o_year': 1994},\n",
       " {'nation': 'ETHIOPIA', 'o_year': 1993},\n",
       " {'nation': 'ETHIOPIA', 'o_year': 1992},\n",
       " {'nation': 'FRANCE', 'o_year': 1998},\n",
       " {'nation': 'FRANCE', 'o_year': 1997},\n",
       " {'nation': 'FRANCE', 'o_year': 1996},\n",
       " {'nation': 'FRANCE', 'o_year': 1995},\n",
       " {'nation': 'FRANCE', 'o_year': 1994},\n",
       " {'nation': 'FRANCE', 'o_year': 1993},\n",
       " {'nation': 'FRANCE', 'o_year': 1992},\n",
       " {'nation': 'GERMANY', 'o_year': 1998},\n",
       " {'nation': 'GERMANY', 'o_year': 1997},\n",
       " {'nation': 'GERMANY', 'o_year': 1996},\n",
       " {'nation': 'GERMANY', 'o_year': 1995},\n",
       " {'nation': 'GERMANY', 'o_year': 1994},\n",
       " {'nation': 'GERMANY', 'o_year': 1993},\n",
       " {'nation': 'GERMANY', 'o_year': 1992},\n",
       " {'nation': 'INDIA', 'o_year': 1998},\n",
       " {'nation': 'INDIA', 'o_year': 1997},\n",
       " {'nation': 'INDIA', 'o_year': 1996},\n",
       " {'nation': 'INDIA', 'o_year': 1995},\n",
       " {'nation': 'INDIA', 'o_year': 1994},\n",
       " {'nation': 'INDIA', 'o_year': 1993},\n",
       " {'nation': 'INDIA', 'o_year': 1992},\n",
       " {'nation': 'INDONESIA', 'o_year': 1998},\n",
       " {'nation': 'INDONESIA', 'o_year': 1997},\n",
       " {'nation': 'INDONESIA', 'o_year': 1996},\n",
       " {'nation': 'INDONESIA', 'o_year': 1995},\n",
       " {'nation': 'INDONESIA', 'o_year': 1994},\n",
       " {'nation': 'INDONESIA', 'o_year': 1993},\n",
       " {'nation': 'INDONESIA', 'o_year': 1992},\n",
       " {'nation': 'IRAN', 'o_year': 1998},\n",
       " {'nation': 'IRAN', 'o_year': 1997},\n",
       " {'nation': 'IRAN', 'o_year': 1996},\n",
       " {'nation': 'IRAN', 'o_year': 1995},\n",
       " {'nation': 'IRAN', 'o_year': 1994},\n",
       " {'nation': 'IRAN', 'o_year': 1993},\n",
       " {'nation': 'IRAN', 'o_year': 1992},\n",
       " {'nation': 'IRAQ', 'o_year': 1998},\n",
       " {'nation': 'IRAQ', 'o_year': 1997},\n",
       " {'nation': 'IRAQ', 'o_year': 1996},\n",
       " {'nation': 'IRAQ', 'o_year': 1995},\n",
       " {'nation': 'IRAQ', 'o_year': 1994},\n",
       " {'nation': 'IRAQ', 'o_year': 1993},\n",
       " {'nation': 'IRAQ', 'o_year': 1992},\n",
       " {'nation': 'JAPAN', 'o_year': 1998},\n",
       " {'nation': 'JAPAN', 'o_year': 1997},\n",
       " {'nation': 'JAPAN', 'o_year': 1996},\n",
       " {'nation': 'JAPAN', 'o_year': 1995},\n",
       " {'nation': 'JAPAN', 'o_year': 1994},\n",
       " {'nation': 'JAPAN', 'o_year': 1993},\n",
       " {'nation': 'JAPAN', 'o_year': 1992},\n",
       " {'nation': 'JORDAN', 'o_year': 1998},\n",
       " {'nation': 'JORDAN', 'o_year': 1997},\n",
       " {'nation': 'JORDAN', 'o_year': 1996},\n",
       " {'nation': 'JORDAN', 'o_year': 1995},\n",
       " {'nation': 'JORDAN', 'o_year': 1994},\n",
       " {'nation': 'JORDAN', 'o_year': 1993},\n",
       " {'nation': 'JORDAN', 'o_year': 1992},\n",
       " {'nation': 'KENYA', 'o_year': 1998},\n",
       " {'nation': 'KENYA', 'o_year': 1997},\n",
       " {'nation': 'KENYA', 'o_year': 1996},\n",
       " {'nation': 'KENYA', 'o_year': 1995},\n",
       " {'nation': 'KENYA', 'o_year': 1994},\n",
       " {'nation': 'KENYA', 'o_year': 1993},\n",
       " {'nation': 'KENYA', 'o_year': 1992},\n",
       " {'nation': 'MOROCCO', 'o_year': 1998},\n",
       " {'nation': 'MOROCCO', 'o_year': 1997},\n",
       " {'nation': 'MOROCCO', 'o_year': 1996},\n",
       " {'nation': 'MOROCCO', 'o_year': 1995},\n",
       " {'nation': 'MOROCCO', 'o_year': 1994},\n",
       " {'nation': 'MOROCCO', 'o_year': 1993},\n",
       " {'nation': 'MOROCCO', 'o_year': 1992},\n",
       " {'nation': 'MOZAMBIQUE', 'o_year': 1998},\n",
       " {'nation': 'MOZAMBIQUE', 'o_year': 1997},\n",
       " {'nation': 'MOZAMBIQUE', 'o_year': 1996},\n",
       " {'nation': 'MOZAMBIQUE', 'o_year': 1995},\n",
       " {'nation': 'MOZAMBIQUE', 'o_year': 1994},\n",
       " {'nation': 'MOZAMBIQUE', 'o_year': 1993},\n",
       " {'nation': 'MOZAMBIQUE', 'o_year': 1992},\n",
       " {'nation': 'PERU', 'o_year': 1998},\n",
       " {'nation': 'PERU', 'o_year': 1997},\n",
       " {'nation': 'PERU', 'o_year': 1996},\n",
       " {'nation': 'PERU', 'o_year': 1995},\n",
       " {'nation': 'PERU', 'o_year': 1994},\n",
       " {'nation': 'PERU', 'o_year': 1993},\n",
       " {'nation': 'PERU', 'o_year': 1992},\n",
       " {'nation': 'ROMANIA', 'o_year': 1998},\n",
       " {'nation': 'ROMANIA', 'o_year': 1997},\n",
       " {'nation': 'ROMANIA', 'o_year': 1996},\n",
       " {'nation': 'ROMANIA', 'o_year': 1995},\n",
       " {'nation': 'ROMANIA', 'o_year': 1994},\n",
       " {'nation': 'ROMANIA', 'o_year': 1993},\n",
       " {'nation': 'ROMANIA', 'o_year': 1992},\n",
       " {'nation': 'RUSSIA', 'o_year': 1998},\n",
       " {'nation': 'RUSSIA', 'o_year': 1997},\n",
       " {'nation': 'RUSSIA', 'o_year': 1996},\n",
       " {'nation': 'RUSSIA', 'o_year': 1995},\n",
       " {'nation': 'RUSSIA', 'o_year': 1994},\n",
       " {'nation': 'RUSSIA', 'o_year': 1993},\n",
       " {'nation': 'RUSSIA', 'o_year': 1992},\n",
       " {'nation': 'SAUDI ARABIA', 'o_year': 1998},\n",
       " {'nation': 'SAUDI ARABIA', 'o_year': 1997},\n",
       " {'nation': 'SAUDI ARABIA', 'o_year': 1996},\n",
       " {'nation': 'SAUDI ARABIA', 'o_year': 1995},\n",
       " {'nation': 'SAUDI ARABIA', 'o_year': 1994},\n",
       " {'nation': 'SAUDI ARABIA', 'o_year': 1993},\n",
       " {'nation': 'SAUDI ARABIA', 'o_year': 1992},\n",
       " {'nation': 'UNITED KINGDOM', 'o_year': 1998},\n",
       " {'nation': 'UNITED KINGDOM', 'o_year': 1997},\n",
       " {'nation': 'UNITED KINGDOM', 'o_year': 1996},\n",
       " {'nation': 'UNITED KINGDOM', 'o_year': 1995},\n",
       " {'nation': 'UNITED KINGDOM', 'o_year': 1994},\n",
       " {'nation': 'UNITED KINGDOM', 'o_year': 1993},\n",
       " {'nation': 'UNITED KINGDOM', 'o_year': 1992},\n",
       " {'nation': 'UNITED STATES', 'o_year': 1998},\n",
       " {'nation': 'UNITED STATES', 'o_year': 1997},\n",
       " {'nation': 'UNITED STATES', 'o_year': 1996},\n",
       " {'nation': 'UNITED STATES', 'o_year': 1995},\n",
       " {'nation': 'UNITED STATES', 'o_year': 1994},\n",
       " {'nation': 'UNITED STATES', 'o_year': 1993},\n",
       " {'nation': 'UNITED STATES', 'o_year': 1992},\n",
       " {'nation': 'VIETNAM', 'o_year': 1998},\n",
       " {'nation': 'VIETNAM', 'o_year': 1997},\n",
       " {'nation': 'VIETNAM', 'o_year': 1996},\n",
       " {'nation': 'VIETNAM', 'o_year': 1995},\n",
       " {'nation': 'VIETNAM', 'o_year': 1994},\n",
       " {'nation': 'VIETNAM', 'o_year': 1993},\n",
       " {'nation': 'VIETNAM', 'o_year': 1992}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are all the possible group-by key combinations?\n",
    "allgroups: pl.DataFrame = listdf.select(INDEX_COLS or pl.lit(0).alias(\"\"))\n",
    "allgroups.to_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a91406e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T08:54:05.013241Z",
     "iopub.status.busy": "2025-05-01T08:54:05.013142Z",
     "iopub.status.idle": "2025-05-01T08:54:05.028428Z",
     "shell.execute_reply": "2025-05-01T08:54:05.028163Z"
    },
    "papermill": {
     "duration": 0.017933,
     "end_time": "2025-05-01T08:54:05.029178",
     "exception": false,
     "start_time": "2025-05-01T08:54:05.011245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Template for the final output, including all possible group-by groups\n",
    "# Obtained by collecting all the samples in a big table and then keeping only the first occurrence of each groupby key.\n",
    "# Then, fill all OUTPUT_COLS with nulls\n",
    "templatedf = dfsdf.drop(\"sample\").group_by(INDEX_COLS or pl.lit(0).alias(\"\"), maintain_order=True).first()\n",
    "templatedf = templatedf.clear(n=len(allgroups)).with_columns(allgroups)\n",
    "templatedf\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/template.pkl\", \"wb\") as f:\n",
    "    pickle.dump(templatedf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cc2d8a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T08:54:05.032929Z",
     "iopub.status.busy": "2025-05-01T08:54:05.032839Z",
     "iopub.status.idle": "2025-05-01T08:54:05.376501Z",
     "shell.execute_reply": "2025-05-01T08:54:05.376175Z"
    },
    "papermill": {
     "duration": 0.346414,
     "end_time": "2025-05-01T08:54:05.377359",
     "exception": false,
     "start_time": "2025-05-01T08:54:05.030945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write all table entries in the output table to their own JSON files. Each file has a number, the information of which file corresponds to which table entry\n",
    "# is stored in reverse_map.json (as well as in the files themselves)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/json\", exist_ok=True)\n",
    "i: int = 0\n",
    "for col in OUTPUT_COLS:\n",
    "    for group in allgroups.iter_rows(named=True):\n",
    "        values = listdf.filter(pl.col(k).eq(v) for k, v in group.items()).select(col).to_series()\n",
    "        j = pl.DataFrame().with_columns([\n",
    "            pl.lit(col).alias(\"col\"),\n",
    "            pl.lit(group).alias(\"row\"),\n",
    "            pl.lit(values.explode().dtype.__repr__()).alias(\"dtype\"),\n",
    "            values.alias(\"values\"),\n",
    "        ])\n",
    "        j.write_json(f\"{OUTPUT_DIR}/json/{i}.json\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1710606f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T08:54:05.381912Z",
     "iopub.status.busy": "2025-05-01T08:54:05.381796Z",
     "iopub.status.idle": "2025-05-01T08:54:07.647783Z",
     "shell.execute_reply": "2025-05-01T08:54:07.647539Z"
    },
    "papermill": {
     "duration": 2.269031,
     "end_time": "2025-05-01T08:54:07.648481",
     "exception": false,
     "start_time": "2025-05-01T08:54:05.379450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michael/projects/dpdb/pacdb/outputs/ap-duckdb-q9-customer-step1.zip'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip the OUTPUT_DIR\n",
    "shutil.make_archive(OUTPUT_DIR, 'zip', OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21.25244,
   "end_time": "2025-05-01T08:54:08.169169",
   "environment_variables": {},
   "exception": null,
   "input_path": "autopac-duckdb-step1.ipynb",
   "output_path": "./ap-duckdb-q9-customer-step1.ipynb",
   "parameters": {
    "EXPERIMENT": "ap-duckdb-q9-customer",
    "INDEX_COLS": [
     "nation",
     "o_year"
    ],
    "OUTPUT_COLS": [
     "sum_profit"
    ],
    "OUTPUT_DIR": "./outputs/ap-duckdb-q9-customer-step1",
    "PREPARE_STEP": "DEALLOCATE PREPARE run_query;\n\nPREPARE run_query AS \nSELECT\n    nation,\n    o_year,\n    sum(amount) AS sum_profit\nFROM (\n    SELECT\n        n_name AS nation,\n        extract(year FROM o_orderdate) AS o_year,\n        l_extendedprice * (1 - l_discount) - ps_supplycost * l_quantity AS amount\n    FROM\n        part,\n        supplier,\n        lineitem,\n        partsupp,\n        orders,\n        nation,\n        customer,\n        random_samples AS rs\n    WHERE\n        rs.row_id = customer.rowid\n        AND rs.random_binary = TRUE\n        AND rs.sample_id = $sample\n        AND o_custkey = c_custkey\n        AND s_suppkey = l_suppkey\n        AND ps_suppkey = l_suppkey\n        AND ps_partkey = l_partkey\n        AND p_partkey = l_partkey\n        AND o_orderkey = l_orderkey\n        AND s_nationkey = n_nationkey\n        AND p_name LIKE '%green%') AS profit\nGROUP BY\n    nation,\n    o_year\nORDER BY\n    nation,\n    o_year DESC;",
    "SAMPLES": 1024,
    "SAMPLE_STEP": "DROP TABLE IF EXISTS random_samples;\n\nCREATE TABLE random_samples AS\nWITH sample_numbers AS MATERIALIZED (\n    SELECT range AS sample_id FROM range(1024 // 2)\n), random_values AS MATERIALIZED (\n    SELECT \n        sample_numbers.sample_id,\n        customer.rowid AS row_id,\n        (RANDOM() > 0.5)::BOOLEAN AS random_binary\n    FROM sample_numbers\n    JOIN customer ON TRUE  -- Cross join to duplicate rows for each sample\n)\nSELECT\n    sample_id,\n    row_id,\n    random_binary\nFROM random_values\nUNION ALL\nSELECT -- select the complementary samples too\n    (1024 // 2) + sample_id,\n    row_id,\n    NOT random_binary  -- Inverse the random_binary to get the complementary sample\nFROM random_values\nORDER BY sample_id, row_id;"
   },
   "start_time": "2025-05-01T08:53:46.916729",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}