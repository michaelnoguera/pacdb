{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/09 13:52:30 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pyspark.sql\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark: SparkSession = (SparkSession.builder.appName(\"pacdb\")\n",
    "         .config(\"spark.executor.memory\", \"512M\")\n",
    "         .config(\"spark.sql.warehouse.dir\", \".spark\")\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate())\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set font to Times New Roman\n",
    "LATEX = False\n",
    "if LATEX:\n",
    "    mpl.rcParams['text.usetex'] = True\n",
    "    mpl.rcParams[\"font.family\"] = \"serif\"\n",
    "    mpl.rcParams[\"font.serif\"] = \"Times\"\n",
    "else:\n",
    "    mpl.rcParams['text.usetex'] = False\n",
    "    mpl.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "    mpl.rcParams[\"mathtext.fontset\"] = \"stix\"\n",
    "    \n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "mpl.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "import matplotlib_inline.backend_inline  # type: ignore\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "mpl.rcParams['axes.titleweight'] = 'bold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_df: pyspark.sql.DataFrame = spark.read.csv(\"./data/student_performance/student-mat.csv\", header=True, inferSchema=True, sep=\";\")\n",
    "#portuguese_df = spark.read.csv(\"./data/student_performance/student-por.csv\", header=True, inferSchema=True, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaitanyasuma/Library/Python/3.9/lib/python/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pacdb import PACDataFrame, PACOptions, SamplerOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = math_df\n",
    "\n",
    "query_name: str = \"count\"\n",
    "budget_list: List[float] = [1/64, 1/32, 1/16, 1/8, 1/4, 1/2, 1., 2., 4.]\n",
    "sample_size: int = 3\n",
    "sampling_rate: float = 0.5\n",
    "m: int = 10\n",
    "c: float = 1e-6\n",
    "mi: float = 1./4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found output format of query: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/sql/pandas/serializers.py:224: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(series.dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     0.0|\n",
      "+--------+\n",
      "\n",
      "max_mi: 0.25, eta: 0.05, dimensions: 1\n",
      "Using the identity matrix as the projection matrix.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6b6072c8204b3aabb2815920097d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 291 trials\n",
      "Final variance estimates: [36.90320142653015]\n",
      "sqrt total var is 6.074800525657625\n",
      "Computed noise (variances) is [73.8064028530603]\n",
      "Sample: [90] + Noise: [73.8064028530603] = Noised: [75.40049736497639]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/sql/pandas/serializers.py:224: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(series.dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting to dataframe:\n",
      "+-----------------+\n",
      "|         count(1)|\n",
      "+-----------------+\n",
      "|75.40049736497639|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[count(1): double]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query(df):\n",
    "    return df.filter(df[\"absences\"] >= 5).agg(F.count(\"*\"))\n",
    "\n",
    "pac_df = (PACDataFrame.fromDataFrame(df)\n",
    "                    .withOptions(PACOptions(trials = m, max_mi = mi, c = c))\n",
    "                    .withSamplerOptions(SamplerOptions(fraction=sampling_rate))\n",
    "                    .withQuery(lambda x: query(x)))\n",
    "\n",
    "pac_df.releaseValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found output format of query: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/sql/pandas/serializers.py:224: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(series.dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|guardian|count(1)|\n",
      "+--------+--------+\n",
      "|  father|     0.0|\n",
      "|  mother|     0.0|\n",
      "|   other|     0.0|\n",
      "+--------+--------+\n",
      "\n",
      "max_mi: 0.25, eta: 0.05, dimensions: 3\n",
      "Using the identity matrix as the projection matrix.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22feadda39484c0a907ea37edb51dce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 1301 trials\n",
      "Final variance estimates: [21.487457469303163, 70.25039687439629, 7.937531645083514]\n",
      "sqrt total var is 9.983756106234916\n",
      "Computed noise (variances) is [92.55853536374374, 167.35872160506773, 56.25572079431135]\n",
      "Sample: [ 49 136  17] + Noise: [92.55853536374374, 167.35872160506773, 56.25572079431135] = Noised: [48.825404333419996, 100.16134904466116, 19.554682773846373]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/sql/pandas/serializers.py:224: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(series.dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting to dataframe:\n",
      "+--------+------------------+\n",
      "|guardian|          count(1)|\n",
      "+--------+------------------+\n",
      "|  father|48.825404333419996|\n",
      "|  mother|100.16134904466116|\n",
      "|   other|19.554682773846373|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[guardian: string, count(1): double]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query(df):\n",
    "    return df.groupBy(F.col(\"guardian\")).agg(F.count(\"*\"))\n",
    "\n",
    "pac_df = (PACDataFrame.fromDataFrame(df)\n",
    "                    .withOptions(PACOptions(trials = m, max_mi = mi, c = c))\n",
    "                    .withSamplerOptions(SamplerOptions(fraction=sampling_rate))\n",
    "                    .withQuery(lambda x: query(x)))\n",
    "\n",
    "pac_df.releaseValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|guardian|count(1)|\n",
      "+--------+--------+\n",
      "|  father|      90|\n",
      "|  mother|     273|\n",
      "|   other|      32|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found output format of query: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/sql/pandas/serializers.py:224: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(series.dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+-------------+\n",
      "|guardian|avg(absences)|max(absences)|\n",
      "+--------+-------------+-------------+\n",
      "|  father|          0.0|          0.0|\n",
      "|  mother|          0.0|          0.0|\n",
      "|   other|          0.0|          0.0|\n",
      "+--------+-------------+-------------+\n",
      "\n",
      "max_mi: 0.25, eta: 0.05, dimensions: 6\n",
      "Using the identity matrix as the projection matrix.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17029cf5dfa4a4faff2ec3b5c31bc48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 2031 trials\n",
      "Final variance estimates: [0.2673946669479816, 0.2610972296632544, 3.4483907699257403, 6.138180215522039, 243.33233986939516, 65.47905155951779]\n",
      "sqrt total var is 17.858512096783763\n",
      "Computed noise (variances) is [18.46935115605126, 18.250568614365882, 66.32595393452247, 88.49018142275902, 557.1539118546636, 289.01904259423685]\n",
      "Sample: [ 4.825       6.0738255   8.88888889 21.         75.         40.        ] + Noise: [18.46935115605126, 18.250568614365882, 66.32595393452247, 88.49018142275902, 557.1539118546636, 289.01904259423685] = Noised: [13.888134009570617, -14.747491301075355, 11.092936084403693, -93.90990460306088, -299.8511359518356, 396.8721673352766]\n",
      "Inserting to dataframe:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/sql/pandas/serializers.py:224: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(series.dtype):\n",
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+------------------+\n",
      "|guardian|      avg(absences)|     max(absences)|\n",
      "+--------+-------------------+------------------+\n",
      "|  father| 13.888134009570617|-93.90990460306088|\n",
      "|  mother|-14.747491301075355|-299.8511359518356|\n",
      "|   other| 11.092936084403693| 396.8721673352766|\n",
      "+--------+-------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[guardian: string, avg(absences): double, max(absences): double]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query(df):\n",
    "    return df.groupBy(F.col(\"guardian\")).agg(F.avg(\"absences\"), F.max(\"absences\"))\n",
    "\n",
    "pac_df = (PACDataFrame.fromDataFrame(df)\n",
    "                    .withOptions(PACOptions(trials = m, max_mi = mi, c = c))\n",
    "                    .withSamplerOptions(SamplerOptions(fraction=sampling_rate))\n",
    "                    .withQuery(lambda x: query(x)))\n",
    "\n",
    "pac_df.releaseValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion between dataframes and numpy vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151]\n",
      "[ 90 273  32]\n",
      "[ 3.97777778  5.83516484  9.5        21.         75.         40.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/sql/pandas/serializers.py:224: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(series.dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count(1)\n",
      "0       151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/sql/pandas/serializers.py:224: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(series.dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count(1)\n",
      "0        90\n",
      "1       273\n",
      "2        32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/sql/pandas/serializers.py:224: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(series.dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg(absences)  max(absences)\n",
      "0       3.977778           21.0\n",
      "1       5.835165           75.0\n",
      "2       9.500000           40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     151|\n",
      "+--------+\n",
      "\n",
      "+--------+--------+\n",
      "|guardian|count(1)|\n",
      "+--------+--------+\n",
      "|  father|      90|\n",
      "|  mother|     273|\n",
      "|   other|      32|\n",
      "+--------+--------+\n",
      "\n",
      "+--------+-----------------+-------------+\n",
      "|guardian|    avg(absences)|max(absences)|\n",
      "+--------+-----------------+-------------+\n",
      "|  father|3.977777777777778|         21.0|\n",
      "|  mother|5.835164835164835|         75.0|\n",
      "|   other|              9.5|         40.0|\n",
      "+--------+-----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "import pyspark.sql.dataframe\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "df = math_df\n",
    "\n",
    "def _unwrapDataFrame(df: pyspark.sql.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert a PySpark DataFrame into a numpy vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    numeric_columns: List[str] = [f.name for f in df.schema.fields if isinstance(f.dataType, T.NumericType)]\n",
    "    df_numeric: pyspark.sql.DataFrame = df.select(*numeric_columns)  # select only numeric columns\n",
    "    np_array: np.ndarray = np.array(df_numeric.collect())\n",
    "\n",
    "    flat: np.ndarray = np_array.flatten(order=\"F\")\n",
    "\n",
    "    return flat\n",
    "\n",
    "def _updateDataFrame(vec: np.ndarray, df: pyspark.sql.DataFrame) -> pyspark.sql.DataFrame:\n",
    "    \"\"\"\n",
    "    Use the values of the numpy vector to update the PySpark DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    numeric_columns: List[str] = [f.name for f in df.schema.fields if isinstance(f.dataType, T.NumericType)]\n",
    "    df_numeric: pyspark.sql.DataFrame = df.select(*numeric_columns)  # select only numeric columns\n",
    "    shape = np.array(df_numeric.collect()).shape\n",
    "\n",
    "    np_array = vec.reshape(shape, order=\"F\")\n",
    "    new_pandas: ps.DataFrame = ps.DataFrame(np_array, columns=numeric_columns)\n",
    "    print(new_pandas)\n",
    "\n",
    "    old_pandas = df.pandas_api()\n",
    "    old_pandas.update(new_pandas)\n",
    "\n",
    "    return old_pandas.to_spark()\n",
    "\n",
    "\n",
    "u1 = _unwrapDataFrame(df.filter(df[\"absences\"] >= 5).agg(F.count(\"*\")))\n",
    "u2 = _unwrapDataFrame(df.groupBy(F.col(\"guardian\")).agg(F.count(\"*\")))\n",
    "u3 = _unwrapDataFrame(df.groupBy(F.col(\"guardian\")).agg(F.avg(\"absences\"), F.max(\"absences\")))\n",
    "\n",
    "print(u1)\n",
    "print(u2)\n",
    "print(u3)\n",
    "\n",
    "r1 = _updateDataFrame(u1, df.filter(df[\"absences\"] >= 5).agg(F.count(\"*\")))\n",
    "r2 = _updateDataFrame(u2, df.groupBy(F.col(\"guardian\")).agg(F.count(\"*\")))\n",
    "r3 = _updateDataFrame(u3, df.groupBy(F.col(\"guardian\")).agg(F.avg(\"absences\"), F.max(\"absences\")))\n",
    "\n",
    "r1.show()\n",
    "r2.show()\n",
    "r3.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
