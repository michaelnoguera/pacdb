{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = 'dp-q1-count-order-N-O'\n",
    "OUTPUT_DIR = f'../dp/{EXPERIMENT}'\n",
    "\n",
    "import os\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import concurrent.futures\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pickle\n",
    "from numpy.random import laplace\n",
    "from functools import reduce\n",
    "import operator\n",
    "from IPython.display import display, HTML\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600572, 16)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Data Setup\n",
    "lineitem_df = pd.read_parquet('../data/tpch/lineitem.parquet')\n",
    "\n",
    "lineitem_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineitem_filtered = lineitem_df[\n",
    "        (lineitem_df['l_shipdate'] <= date(1998, 9, 2)) &\n",
    "        (lineitem_df['l_returnflag'] == 'N') &\n",
    "        (lineitem_df['l_linestatus'] == 'O')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mayuri's conversion functions between DP epsilon and PAC MI using posterior advantage for equivalence\n",
    "def calc_posterior(mi, prior=0.5, prec = 100000):\n",
    "    test_vals = [x / prec for x in range(1, prec)]\n",
    "    max_t = None\n",
    "    for t in test_vals:\n",
    "        if t*np.log(t/prior)+(1-t)*np.log((1-t)/(1-prior)) <= mi:\n",
    "            if  max_t is None or t > max_t:\n",
    "                max_t = t\n",
    "    return max_t\n",
    "\n",
    "def dp_epsilon_to_posterior_success(epsilon):\n",
    "    return 1 - 1./(1+np.exp(epsilon))\n",
    "\n",
    "def dp_ps_to_epsilon(ps):\n",
    "    return np.log(ps / (1-ps))\n",
    "\n",
    "# example usage:\n",
    "# dp_ps_to_epsilon(calc_posterior(1/256.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mi_list = [1/256., 1/128., 1/64., 1/16., 1/4., 1., 2., 4., 16.]\n",
    "mi_list = [0.001248318631131131, 1/64, 1/32, 1/16, 1/4, 1., 2., 4., 16.]\n",
    "eps_list = [(dp_ps_to_epsilon(calc_posterior(mi))) for mi in mi_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "true_count = 3765\n",
    "# for every epsilon, there are 100 values of abs dp noise, \n",
    "# and 100 values of noisy results\n",
    "# for the eps vs noise graph, we take the avg of dp noise per epsilon\n",
    "# for the other graph, we plot all points on the y-axis\n",
    "\n",
    "def run_dp(df, eps_list, prefix, true_result):\n",
    "    dp_noise_list = []\n",
    "    dp_result_list = []\n",
    "    scales = []\n",
    "    for eps in eps_list:\n",
    "        if prefix == 'count':\n",
    "            sensitivity = 1  # Sensitivity for count queries is always 1\n",
    "        # elif prefix == 'mean':\n",
    "        #     max_absences = np.max(df[\"absences\"])\n",
    "        #     min_absences = np.min(df[\"absences\"])\n",
    "        #     n = len(df)\n",
    "        #     sensitivity = (max_absences - min_absences) / n \n",
    "        # elif prefix == 'sum':\n",
    "        #     max_absences = np.max(df[\"absences\"])\n",
    "        #     sensitivity = max_absences\n",
    "        scale = sensitivity / eps  # Scale parameter for Laplace noise\n",
    "        scales.append(scale)\n",
    "        \n",
    "        all_noise = []\n",
    "        all_abs_noise = []\n",
    "        all_noisy_result = []\n",
    "        # for every epsilon, get 100 values\n",
    "        for i in range(100):\n",
    "            noise = np.random.laplace(loc=0, scale=scale)\n",
    "            all_noise.append(noise)\n",
    "            all_abs_noise.append(np.abs(noise))\n",
    "            all_noisy_result.append(true_result + noise)\n",
    "    \n",
    "        dp_noise_list.append(all_abs_noise) # list of lists\n",
    "        dp_result_list.append(all_noisy_result)\n",
    "    \n",
    "    return scales, dp_noise_list, dp_result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale, dp_noise_list, dp_result_list = run_dp(lineitem_filtered, eps_list, 'count', true_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_of_count = [1/item for item in eps_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def save_results(list, mi_list, prefix: str, type_of_list: str):\n",
    "\n",
    "    flattened_eps = [eps for eps, results in zip(mi_list, list) for _ in results]\n",
    "    flattened_values = [val for results in list for val in results]\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'mi': flattened_eps,\n",
    "        'count_order': flattened_values\n",
    "    })\n",
    "\n",
    "    df.to_csv(f'{OUTPUT_DIR}/dp_basic_{prefix}_{type_of_list}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_results(list=scale, mi_list=mi_list, prefix=\"count\", type_of_list=\"variances\")\n",
    "save_results(list=dp_noise_list, mi_list=mi_list, prefix=\"count\", type_of_list=\"noise\")\n",
    "save_results(list=dp_result_list, mi_list=mi_list, prefix=\"count\", type_of_list=\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_scaled_error(est: np.ndarray, actual: np.ndarray) -> np.ndarray:\n",
    "    return np.abs(est - actual)\n",
    "def relative_error_percent(est: np.ndarray, actual: np.ndarray) -> np.ndarray:\n",
    "    return (np.abs(est - actual) / actual) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_COLS = ['count_order']\n",
    "ERROR_COLS = [*[f'absolute error {i}' for i in OUTPUT_COLS], *[f'relative error {i}' for i in OUTPUT_COLS]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi</th>\n",
       "      <th>count_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001248</td>\n",
       "      <td>3763.156900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001248</td>\n",
       "      <td>3763.722172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001248</td>\n",
       "      <td>3769.203896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001248</td>\n",
       "      <td>3759.416009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001248</td>\n",
       "      <td>3797.651608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>3765.188697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>3764.873477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>3765.020582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>3764.910237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>3764.981504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            mi  count_order\n",
       "0     0.001248  3763.156900\n",
       "1     0.001248  3763.722172\n",
       "2     0.001248  3769.203896\n",
       "3     0.001248  3759.416009\n",
       "4     0.001248  3797.651608\n",
       "..         ...          ...\n",
       "895  16.000000  3765.188697\n",
       "896  16.000000  3764.873477\n",
       "897  16.000000  3765.020582\n",
       "898  16.000000  3764.910237\n",
       "899  16.000000  3764.981504\n",
       "\n",
       "[900 rows x 2 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_results_df = pd.read_csv(f\"{OUTPUT_DIR}/dp_basic_count_results.csv\")\n",
    "\n",
    "dp_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_list = []\n",
    "for i, row in dp_results_df.iterrows():\n",
    "    mi = row['mi']\n",
    "    r = row[OUTPUT_COLS].to_numpy()\n",
    "    errors_list.append([mi, *absolute_scaled_error(r, true_count), *relative_error_percent(r, true_count)])\n",
    "dp_errors_df = pd.DataFrame(errors_list, columns=['mi', *ERROR_COLS])\n",
    "dp_errors_df.to_csv(f\"{OUTPUT_DIR}/dp-q1-errors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_avg = dp_errors_df.groupby('mi')[['absolute error count_order', 'relative error count_order']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          mi  absolute error count_order  relative error count_order\n",
      "0   0.001248                   10.507145                    0.279074\n",
      "1   0.015625                    3.066360                    0.081444\n",
      "2   0.031250                    2.263352                    0.060116\n",
      "3   0.062500                    1.247529                    0.033135\n",
      "4   0.250000                    0.547295                    0.014536\n",
      "5   1.000000                    0.089819                    0.002386\n",
      "6   2.000000                    0.090586                    0.002406\n",
      "7   4.000000                    0.079863                    0.002121\n",
      "8  16.000000                    0.084827                    0.002253\n"
     ]
    }
   ],
   "source": [
    "print(grouped_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
