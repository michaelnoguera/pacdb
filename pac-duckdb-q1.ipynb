{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DuckDB Notebook\n",
    "\n",
    "This notebook generates a bunch of raw outputs, without applying PAC, to be consumed by a second stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE = False, so we will load saved output from files rather than recomputing.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "EXPERIMENT = 'pac-duckdb-q1'\n",
    "OUTPUT_DIR = f'./outputs/{EXPERIMENT}'\n",
    "GENERATE = False\n",
    "USE_EVEN_NUMBER_OF_INPUT_ROWS = False\n",
    "\n",
    "if GENERATE:\n",
    "    print(\"GENERATE = True, so we will generate new samples.\")\n",
    "else:\n",
    "    print(\"GENERATE = False, so we will load saved output from files rather than recomputing.\")\n",
    "\n",
    "import os\n",
    "from typing import List\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import duckdb\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "\n",
    "# duckdb load data/tpch/tpch.duckdb\n",
    "#con = duckdb.connect(database='data/tpch/tpch.duckdb', read_only=True)\n",
    "con = duckdb.connect(database=':memory:')\n",
    "tables = [\"customer\", \"lineitem\", \"nation\", \"orders\", \"part\", \"partsupp\", \"region\", \"supplier\"]\n",
    "#tables = [\"lineitem\", \"orders\"]\n",
    "for t in tables:\n",
    "    con.execute(f\"CREATE TABLE {t} AS SELECT * FROM 'data/tpch/{t}.parquet'\")\n",
    "\n",
    "lineitem_df = con.execute(\"SELECT * FROM lineitem\").fetchdf()\n",
    "orders_df = con.execute(\"SELECT * FROM orders\").fetchdf()\n",
    "\n",
    "row_count = lineitem_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the table of random samples\n",
    "# to use, join it with the lineitem table (for specific sample # s) and filter to just the\n",
    "# rows where random_binary = 1.0\n",
    "# This will give us a 50% sample of the lineitem table for each sample # s\n",
    "\n",
    "SAMPLES = 1024\n",
    "assert SAMPLES % 2 == 0, \"SAMPLES must be even to create complementary samples.\"\n",
    "\n",
    "random_samples = con.execute(f\"\"\"\n",
    "DROP TABLE IF EXISTS random_samples;\n",
    "\n",
    "CREATE TABLE random_samples AS\n",
    "WITH sample_numbers AS MATERIALIZED (\n",
    "    SELECT range AS sample_id FROM range({SAMPLES//2})\n",
    "), random_values AS MATERIALIZED (\n",
    "    SELECT \n",
    "        sample_numbers.sample_id,\n",
    "        customer.rowid AS row_id,\n",
    "        (RANDOM() > 0.5)::BOOLEAN AS random_binary\n",
    "    FROM sample_numbers\n",
    "    JOIN customer ON TRUE  -- Cross join to duplicate rows for each sample\n",
    ")\n",
    "SELECT\n",
    "    sample_id,\n",
    "    row_id,\n",
    "    random_binary\n",
    "FROM random_values\n",
    "UNION ALL\n",
    "SELECT -- select the complementary samples too\n",
    "    ({SAMPLES//2}) + sample_id,\n",
    "    row_id,\n",
    "    NOT random_binary  -- Inverse the random_binary to get the complementary sample\n",
    "FROM random_values\n",
    "ORDER BY sample_id, row_id;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_sizes = con.execute(\"\"\"\n",
    "#SELECT sample_id, SUM(random_binary) AS sample_size\n",
    "#FROM random_samples\n",
    "#GROUP BY sample_id;\n",
    "#\"\"\").pl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The randomness of what rows are chosen is saved to disk in `random_binary.json`. For each sample #, there is an array with one entry per row, where 1 means the row was chosen and 0 means it was not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(f\"\"\"\n",
    "SELECT sample_id, array_agg(random_binary::TINYINT) as random_binary\n",
    "FROM random_samples\n",
    "GROUP BY sample_id;\n",
    "\"\"\").pl().write_json(f\"{OUTPUT_DIR}/random_binary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query is specified as a prepared statement. We will then execute it once per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>l_returnflag</th><th>l_linestatus</th><th>sum_qty</th><th>sum_base_price</th><th>sum_disc_price</th><th>sum_charge</th><th>avg_qty</th><th>avg_price</th><th>avg_disc</th><th>count_order</th></tr><tr><td>str</td><td>str</td><td>decimal[38,2]</td><td>decimal[38,2]</td><td>decimal[38,4]</td><td>decimal[38,6]</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;A&quot;</td><td>&quot;F&quot;</td><td>3765678.00</td><td>5310579266.84</td><td>5045231154.2046</td><td>5246662484.135760</td><td>25.540756</td><td>36019.067451</td><td>0.050009</td><td>147438</td></tr><tr><td>&quot;N&quot;</td><td>&quot;F&quot;</td><td>93438.00</td><td>131037874.62</td><td>124596041.1712</td><td>129711106.186768</td><td>25.404568</td><td>35627.480865</td><td>0.049244</td><td>3678</td></tr><tr><td>&quot;N&quot;</td><td>&quot;O&quot;</td><td>7475738.00</td><td>10544998769.04</td><td>10016860640.3824</td><td>10417431897.867036</td><td>25.571367</td><td>36070.021923</td><td>0.050129</td><td>292348</td></tr><tr><td>&quot;R&quot;</td><td>&quot;F&quot;</td><td>3808224.00</td><td>5370503951.16</td><td>5102266139.5422</td><td>5306502622.807394</td><td>25.515397</td><td>35982.793873</td><td>0.050027</td><td>149252</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬──────────┬───────────┐\n",
       "│ l_returnf ┆ l_linesta ┆ sum_qty   ┆ sum_base_ ┆ … ┆ avg_qty   ┆ avg_price ┆ avg_disc ┆ count_ord │\n",
       "│ lag       ┆ tus       ┆ ---       ┆ price     ┆   ┆ ---       ┆ ---       ┆ ---      ┆ er        │\n",
       "│ ---       ┆ ---       ┆ decimal[3 ┆ ---       ┆   ┆ f64       ┆ f64       ┆ f64      ┆ ---       │\n",
       "│ str       ┆ str       ┆ 8,2]      ┆ decimal[3 ┆   ┆           ┆           ┆          ┆ i64       │\n",
       "│           ┆           ┆           ┆ 8,2]      ┆   ┆           ┆           ┆          ┆           │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪══════════╪═══════════╡\n",
       "│ A         ┆ F         ┆ 3765678.0 ┆ 531057926 ┆ … ┆ 25.540756 ┆ 36019.067 ┆ 0.050009 ┆ 147438    │\n",
       "│           ┆           ┆ 0         ┆ 6.84      ┆   ┆           ┆ 451       ┆          ┆           │\n",
       "│ N         ┆ F         ┆ 93438.00  ┆ 131037874 ┆ … ┆ 25.404568 ┆ 35627.480 ┆ 0.049244 ┆ 3678      │\n",
       "│           ┆           ┆           ┆ .62       ┆   ┆           ┆ 865       ┆          ┆           │\n",
       "│ N         ┆ O         ┆ 7475738.0 ┆ 105449987 ┆ … ┆ 25.571367 ┆ 36070.021 ┆ 0.050129 ┆ 292348    │\n",
       "│           ┆           ┆ 0         ┆ 69.04     ┆   ┆           ┆ 923       ┆          ┆           │\n",
       "│ R         ┆ F         ┆ 3808224.0 ┆ 537050395 ┆ … ┆ 25.515397 ┆ 35982.793 ┆ 0.050027 ┆ 149252    │\n",
       "│           ┆           ┆ 0         ┆ 1.16      ┆   ┆           ┆ 873       ┆          ┆           │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴──────────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query\n",
    "con.execute(\"\"\"\n",
    "DEALLOCATE PREPARE run_query;\n",
    "\n",
    "PREPARE run_query AS \n",
    "SELECT\n",
    "    l_returnflag,\n",
    "    l_linestatus,\n",
    "    2*sum(l_quantity) AS sum_qty,\n",
    "    2*sum(l_extendedprice) AS sum_base_price,\n",
    "    2*sum(l_extendedprice * (1 - l_discount)) AS sum_disc_price,\n",
    "    2*sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) AS sum_charge,\n",
    "    avg(l_quantity) AS avg_qty,\n",
    "    avg(l_extendedprice) AS avg_price,\n",
    "    avg(l_discount) AS avg_disc,\n",
    "    2*count(*) AS count_order\n",
    "FROM\n",
    "    lineitem\n",
    "JOIN orders ON lineitem.l_orderkey = orders.o_orderkey\n",
    "JOIN customer ON orders.o_custkey = customer.c_custkey\n",
    "JOIN random_samples AS rs\n",
    "    ON rs.row_id = customer.rowid\n",
    "WHERE\n",
    "    l_shipdate <= CAST('1998-09-02' AS date)\n",
    "    AND rs.random_binary = TRUE\n",
    "    AND rs.sample_id = $sample\n",
    "GROUP BY\n",
    "    l_returnflag,\n",
    "    l_linestatus\n",
    "ORDER BY\n",
    "    l_returnflag,\n",
    "    l_linestatus;\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"EXECUTE run_query(sample := {0});\").pl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now generate the query result for each sample. The query output of each sample is saved to disk in multiple formats:\n",
    "- `csv` contains one file per sample, with the table written in CSV format. This does not preserve data type information.\n",
    "- `parquet` contains one file per sample, with the table written in Parquet format. This preserves data type information as apache arrow converted types.\n",
    "- `dfs.pkl` contains the python list of polars dataframes in a binary format. This could be used to resume the notebook with the exact same previously-used randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all the queries\n",
    "dfs: List[pl.DataFrame] = []\n",
    "for s in range(SAMPLES):\n",
    "    dfs.append(con.execute(f\"EXECUTE run_query(sample := {s});\").pl())\n",
    "\n",
    "# Save the results to disk\n",
    "os.makedirs(f\"{OUTPUT_DIR}/csv\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/parquet\", exist_ok=True)\n",
    "for i, df in enumerate(dfs):\n",
    "    df.write_csv(f\"{OUTPUT_DIR}/csv/sample_{i}.csv\")\n",
    "    df.write_parquet(f\"{OUTPUT_DIR}/parquet/sample_{i}.parquet\")\n",
    "with open(f\"{OUTPUT_DIR}/dfs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dfs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples have been generated and stored in `outputs/{OUTPUT_DIR}/csv/sample_{i}.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output schema: Schema([('sum_qty', Decimal(precision=38, scale=2)), ('sum_base_price', Decimal(precision=38, scale=2)), ('sum_disc_price', Decimal(precision=38, scale=4)), ('sum_charge', Decimal(precision=38, scale=6)), ('avg_qty', Float64), ('avg_price', Float64), ('avg_disc', Float64), ('count_order', Int64)])\n",
      "Output shape: (4, 8)\n"
     ]
    }
   ],
   "source": [
    "INDEX_COLS = ['l_returnflag', 'l_linestatus']\n",
    "OUTPUT_COLS = ['sum_qty', 'sum_base_price', 'sum_disc_price', 'sum_charge', 'avg_qty', 'avg_price', 'avg_disc', 'count_order']\n",
    "OUTPUT_SCHEMA = dfs[0].select(OUTPUT_COLS).collect_schema()\n",
    "OUTPUT_SHAPE = dfs[0].select(OUTPUT_COLS).to_numpy().shape\n",
    "with open(f\"{OUTPUT_DIR}/schema.txt\", \"w\") as f:\n",
    "    f.write(str(OUTPUT_SCHEMA))\n",
    "print(f\"Output schema: {OUTPUT_SCHEMA}\")\n",
    "print(f\"Output shape: {OUTPUT_SHAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sum_qty</th><th>sum_base_price</th><th>sum_disc_price</th><th>sum_charge</th><th>avg_qty</th><th>avg_price</th><th>avg_disc</th><th>count_order</th></tr><tr><td>decimal[38,2]</td><td>decimal[38,2]</td><td>decimal[38,4]</td><td>decimal[38,6]</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>3765678.00</td><td>5310579266.84</td><td>5045231154.2046</td><td>5246662484.135760</td><td>25.540756</td><td>36019.067451</td><td>0.050009</td><td>147438</td></tr><tr><td>93438.00</td><td>131037874.62</td><td>124596041.1712</td><td>129711106.186768</td><td>25.404568</td><td>35627.480865</td><td>0.049244</td><td>3678</td></tr><tr><td>7475738.00</td><td>10544998769.04</td><td>10016860640.3824</td><td>10417431897.867036</td><td>25.571367</td><td>36070.021923</td><td>0.050129</td><td>292348</td></tr><tr><td>3808224.00</td><td>5370503951.16</td><td>5102266139.5422</td><td>5306502622.807394</td><td>25.515397</td><td>35982.793873</td><td>0.050027</td><td>149252</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 8)\n",
       "┌────────────┬────────────┬────────────┬────────────┬───────────┬───────────┬──────────┬───────────┐\n",
       "│ sum_qty    ┆ sum_base_p ┆ sum_disc_p ┆ sum_charge ┆ avg_qty   ┆ avg_price ┆ avg_disc ┆ count_ord │\n",
       "│ ---        ┆ rice       ┆ rice       ┆ ---        ┆ ---       ┆ ---       ┆ ---      ┆ er        │\n",
       "│ decimal[38 ┆ ---        ┆ ---        ┆ decimal[38 ┆ f64       ┆ f64       ┆ f64      ┆ ---       │\n",
       "│ ,2]        ┆ decimal[38 ┆ decimal[38 ┆ ,6]        ┆           ┆           ┆          ┆ i64       │\n",
       "│            ┆ ,2]        ┆ ,4]        ┆            ┆           ┆           ┆          ┆           │\n",
       "╞════════════╪════════════╪════════════╪════════════╪═══════════╪═══════════╪══════════╪═══════════╡\n",
       "│ 3765678.00 ┆ 5310579266 ┆ 5045231154 ┆ 5246662484 ┆ 25.540756 ┆ 36019.067 ┆ 0.050009 ┆ 147438    │\n",
       "│            ┆ .84        ┆ .2046      ┆ .135760    ┆           ┆ 451       ┆          ┆           │\n",
       "│ 93438.00   ┆ 131037874. ┆ 124596041. ┆ 129711106. ┆ 25.404568 ┆ 35627.480 ┆ 0.049244 ┆ 3678      │\n",
       "│            ┆ 62         ┆ 1712       ┆ 186768     ┆           ┆ 865       ┆          ┆           │\n",
       "│ 7475738.00 ┆ 1054499876 ┆ 1001686064 ┆ 1041743189 ┆ 25.571367 ┆ 36070.021 ┆ 0.050129 ┆ 292348    │\n",
       "│            ┆ 9.04       ┆ 0.3824     ┆ 7.867036   ┆           ┆ 923       ┆          ┆           │\n",
       "│ 3808224.00 ┆ 5370503951 ┆ 5102266139 ┆ 5306502622 ┆ 25.515397 ┆ 35982.793 ┆ 0.050027 ┆ 149252    │\n",
       "│            ┆ .16        ┆ .5422      ┆ .807394    ┆           ┆ 873       ┆          ┆           │\n",
       "└────────────┴────────────┴────────────┴────────────┴───────────┴───────────┴──────────┴───────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0].select(OUTPUT_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpyify(df: pl.DataFrame) -> np.ndarray:\n",
    "    return df.select(OUTPUT_COLS).to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>l_returnflag</th><th>l_linestatus</th><th>sum_qty</th><th>sum_base_price</th><th>sum_disc_price</th><th>sum_charge</th><th>avg_qty</th><th>avg_price</th><th>avg_disc</th><th>count_order</th></tr><tr><td>str</td><td>str</td><td>decimal[38,2]</td><td>decimal[38,2]</td><td>decimal[38,4]</td><td>decimal[38,6]</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;A&quot;</td><td>&quot;F&quot;</td><td>3765678.00</td><td>5310579266.84</td><td>5045231154.2046</td><td>5246662484.135760</td><td>25.540756</td><td>36019.067451</td><td>0.050009</td><td>147438</td></tr><tr><td>&quot;N&quot;</td><td>&quot;F&quot;</td><td>93438.00</td><td>131037874.62</td><td>124596041.1712</td><td>129711106.186768</td><td>25.404568</td><td>35627.480865</td><td>0.049244</td><td>3678</td></tr><tr><td>&quot;N&quot;</td><td>&quot;O&quot;</td><td>7475738.00</td><td>10544998769.04</td><td>10016860640.3824</td><td>10417431897.867036</td><td>25.571367</td><td>36070.021923</td><td>0.050129</td><td>292348</td></tr><tr><td>&quot;R&quot;</td><td>&quot;F&quot;</td><td>3808224.00</td><td>5370503951.16</td><td>5102266139.5422</td><td>5306502622.807394</td><td>25.515397</td><td>35982.793873</td><td>0.050027</td><td>149252</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬──────────┬───────────┐\n",
       "│ l_returnf ┆ l_linesta ┆ sum_qty   ┆ sum_base_ ┆ … ┆ avg_qty   ┆ avg_price ┆ avg_disc ┆ count_ord │\n",
       "│ lag       ┆ tus       ┆ ---       ┆ price     ┆   ┆ ---       ┆ ---       ┆ ---      ┆ er        │\n",
       "│ ---       ┆ ---       ┆ decimal[3 ┆ ---       ┆   ┆ f64       ┆ f64       ┆ f64      ┆ ---       │\n",
       "│ str       ┆ str       ┆ 8,2]      ┆ decimal[3 ┆   ┆           ┆           ┆          ┆ i64       │\n",
       "│           ┆           ┆           ┆ 8,2]      ┆   ┆           ┆           ┆          ┆           │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪══════════╪═══════════╡\n",
       "│ A         ┆ F         ┆ 3765678.0 ┆ 531057926 ┆ … ┆ 25.540756 ┆ 36019.067 ┆ 0.050009 ┆ 147438    │\n",
       "│           ┆           ┆ 0         ┆ 6.84      ┆   ┆           ┆ 451       ┆          ┆           │\n",
       "│ N         ┆ F         ┆ 93438.00  ┆ 131037874 ┆ … ┆ 25.404568 ┆ 35627.480 ┆ 0.049244 ┆ 3678      │\n",
       "│           ┆           ┆           ┆ .62       ┆   ┆           ┆ 865       ┆          ┆           │\n",
       "│ N         ┆ O         ┆ 7475738.0 ┆ 105449987 ┆ … ┆ 25.571367 ┆ 36070.021 ┆ 0.050129 ┆ 292348    │\n",
       "│           ┆           ┆ 0         ┆ 69.04     ┆   ┆           ┆ 923       ┆          ┆           │\n",
       "│ R         ┆ F         ┆ 3808224.0 ┆ 537050395 ┆ … ┆ 25.515397 ┆ 35982.793 ┆ 0.050027 ┆ 149252    │\n",
       "│           ┆           ┆ 0         ┆ 1.16      ┆   ┆           ┆ 873       ┆          ┆           │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴──────────┴───────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tablify(arr: np.ndarray) -> pl.DataFrame:\n",
    "    global OUTPUT_SHAPE, OUTPUT_SCHEMA\n",
    "    return dfs[0].update( # put values back into the original dataframe\n",
    "        pl.DataFrame(\n",
    "            arr.reshape(OUTPUT_SHAPE), # reshape to the original shape\n",
    "            schema=OUTPUT_SCHEMA # coerce numpy array to the correct schema\n",
    "        ) # index cols will be left unchanged (not updated b/c we only update output_cols)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples in numpy format are saved to disk in a variety of ways, all of which contain the same data:\n",
    "- `npy` contains arrays saved in the Numpy format. See https://numpy.org/doc/stable/reference/generated/numpy.lib.format.html\n",
    "- `npcsv` contains numpy arrays saved in the CSV format. These are 1D arrays of whatever data type (probably float) is in the table.\n",
    "- `nparr.npz` contains all the numpy arrays saved in the Numpy format for saving multiple arrays in one file. See https://numpy.org/doc/stable/reference/generated/numpy.savez.html\n",
    "- `nparr.pkl` contains the python list of numpy arrays in a binary format, if you don't want to use the numpy format for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrames to numpy arrays\n",
    "nparr = [numpyify(df) for df in dfs]\n",
    "\n",
    "# Save the numpy arrays to disk\n",
    "os.makedirs(f\"{OUTPUT_DIR}/npy\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/npcsv\", exist_ok=True)\n",
    "for i, arr in enumerate(nparr):\n",
    "    np.save(f\"{OUTPUT_DIR}/npy/arr_{i}.npy\", arr)\n",
    "    np.savetxt(f\"{OUTPUT_DIR}/npcsv/arr_{i}.csv\", [arr], delimiter=\",\")\n",
    "np.savez(f\"{OUTPUT_DIR}/nparr.npz\", *nparr)\n",
    "with open(f\"{OUTPUT_DIR}/nparr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(nparr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how to load the `npz` file into an array of 'samples' where the samples are each a 1d numpy array.\n",
    "```python\n",
    "test = np.load(f\"{OUTPUT_DIR}/nparr.npz\")\n",
    "npsamples = [test[f'arr_{i}'] for i in range(SAMPLES)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.load(f\"{OUTPUT_DIR}/nparr.npz\")\n",
    "npsamples = [test[f'arr_{i}'] for i in range(SAMPLES)]\n",
    "npsamples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michael/projects/dpdb/pacdb/outputs/pac-duckdb-q1.zip'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip the OUTPUT_DIR\n",
    "import shutil\n",
    "shutil.make_archive(OUTPUT_DIR, 'zip', OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
