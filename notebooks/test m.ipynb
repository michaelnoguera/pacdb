{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "91016f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars.selectors as cs\n",
    "import numpy as np\n",
    "import json\n",
    "import polars as pl\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d2617142",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = {\n",
    "    1: ['l_returnflag', 'l_linestatus'],\n",
    "    3: ['l_orderkey','o_orderdate','o_shippriority'],\n",
    "    4: ['o_orderpriority'],\n",
    "    5: ['n_name'],\n",
    "    6: [],\n",
    "    7: ['supp_nation', 'cust_nation', 'l_year'], \n",
    "    8: ['o_year'],\n",
    "    9: ['nation', 'o_year'],\n",
    "    10: ['c_custkey', 'c_name', 'c_acctbal', 'c_phone', 'n_name', 'c_address', 'c_comment'],\n",
    "    12: ['l_shipmode'],\n",
    "    13: ['c_count'],\n",
    "    14: [],\n",
    "    \n",
    "    17: [],\n",
    "    19: [],\n",
    "    20: [],\n",
    "    21: ['s_name'],\n",
    "    22: ['cntrycode']\n",
    "}\n",
    "scale_required = set([4, 5, 6, 7, 9, 12, 13, 17, 19, 21, 22])\n",
    "# not 8, 14\n",
    "# skip 3, skip 20\n",
    "# skip 13, 19, 21 for now\n",
    "queries_to_run = [1, 4, 5, 6, 7, 8, 9, 12, 14, 17, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b30417c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m_diffs(dfs, index_cols, pct_diff_cols):\n",
    "    \"\"\"\n",
    "    Filter and join approach: separate m=128 and m=1024, then join and calculate\n",
    "    \"\"\"\n",
    "    # Split into two dataframes based on m value\n",
    "    df_128=dfs[0]\n",
    "    df_1024 = dfs[1]\n",
    "    # Join the two dataframes\n",
    "    if len(index_cols) > 0:\n",
    "        comparison_df = df_128.join(df_1024, on=index_cols, suffix=\"_1024\")\n",
    "    else:\n",
    "        comparison_df = df_128.join(df_1024, how='cross', suffix=\"_1024\")\n",
    "    \n",
    "    # Calculate differences for each pct_diff column\n",
    "    diff_expressions = []\n",
    "    for col in pct_diff_cols:\n",
    "        diff_expr = (pl.col(f\"{col}_1024\") - pl.col(col)).alias(f\"m_diff_{col}\")\n",
    "        diff_expressions.append(diff_expr)\n",
    "    \n",
    "    result = comparison_df.with_columns(diff_expressions)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d3808037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.14970810098791532 -0.4891350586952967\n",
      "\n",
      "\n",
      "\n",
      "4 0.029338246300750548 -0.906178110889087\n",
      "\n",
      "\n",
      "\n",
      "5 2.6850459664211 -0.76946879691803\n",
      "\n",
      "\n",
      "\n",
      "6 -0.15236767563117004 -0.15236767563117004\n",
      "\n",
      "\n",
      "\n",
      "7 3.4557523048117638 -1.4371711407582772\n",
      "\n",
      "\n",
      "\n",
      "8 11.37580973514926 2.745425504196646\n",
      "shape: (2, 12)\n",
      "┌────────┬───────────┬─────────────┬─────────────┬───┬─────────────┬─────────┬────────┬────────────┐\n",
      "│ o_year ┆ mkt_share ┆ mkt_share_n ┆ pct_diff_mk ┆ … ┆ pct_diff_mk ┆ mi_1024 ┆ m_1024 ┆ m_diff_pct │\n",
      "│ ---    ┆ ---       ┆ oised       ┆ t_share     ┆   ┆ t_share_102 ┆ ---     ┆ ---    ┆ _diff_mkt_ │\n",
      "│ i64    ┆ f64       ┆ ---         ┆ ---         ┆   ┆ 4           ┆ f64     ┆ i64    ┆ share      │\n",
      "│        ┆           ┆ list[f64]   ┆ f64         ┆   ┆ ---         ┆         ┆        ┆ ---        │\n",
      "│        ┆           ┆             ┆             ┆   ┆ f64         ┆         ┆        ┆ f64        │\n",
      "╞════════╪═══════════╪═════════════╪═════════════╪═══╪═════════════╪═════════╪════════╪════════════╡\n",
      "│ 1995   ┆ 0.028649  ┆ [0.031424,  ┆ 118.038236  ┆ … ┆ 129.414045  ┆ 0.0625  ┆ 1024   ┆ 11.37581   │\n",
      "│        ┆           ┆ -0.027391,  ┆             ┆   ┆             ┆         ┆        ┆            │\n",
      "│        ┆           ┆ … 0.1011…   ┆             ┆   ┆             ┆         ┆        ┆            │\n",
      "│ 1996   ┆ 0.01825   ┆ [0.033052,  ┆ 114.48725   ┆ … ┆ 117.232676  ┆ 0.0625  ┆ 1024   ┆ 2.745426   │\n",
      "│        ┆           ┆ 0.011547, … ┆             ┆   ┆             ┆         ┆        ┆            │\n",
      "│        ┆           ┆ 0.04928…    ┆             ┆   ┆             ┆         ┆        ┆            │\n",
      "└────────┴───────────┴─────────────┴─────────────┴───┴─────────────┴─────────┴────────┴────────────┘\n",
      "\n",
      "\n",
      "\n",
      "9 4.139746604883552 -3.881185857011733\n",
      "\n",
      "\n",
      "\n",
      "12 0.42419590515780214 -0.7502897882483737\n",
      "\n",
      "\n",
      "\n",
      "14 -0.05632625621077825 -0.05632625621077825\n",
      "\n",
      "\n",
      "\n",
      "17 0.22777688244890726 0.22777688244890726\n",
      "\n",
      "\n",
      "\n",
      "22 3.1033074964962317 -4.144528256674651\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mi=1/16.\n",
    "for query_ind in queries_to_run:\n",
    "    dfs = []\n",
    "    for m in [128, 1024]:\n",
    "        null_info = {}\n",
    "        orig = pl.read_csv(f'../unnoised/q{query_ind}.csv')\n",
    "        if query_ind == 22:\n",
    "            orig = orig.select(\n",
    "            pl.col(\"cntrycode\").cast(str),\n",
    "            pl.col(\"numcust\"),\n",
    "            pl.col(\"totacctbal\"))\n",
    "        if query_ind == 10:\n",
    "            orig = orig.select(\n",
    "                pl.col(\"c_custkey\"), pl.col(\"c_name\"),\n",
    "                pl.col(\"c_acctbal\").cast(str),\n",
    "                pl.col(\"n_name\"), pl.col(\"c_address\"), pl.col(\"c_phone\"), pl.col(\"c_comment\")\n",
    "            )\n",
    "        noised = pl.read_json(f'../outputs/m={m}/ap-duckdb-q{query_ind}-customer-{mi}-step3/output.json')\n",
    "        if index_cols[query_ind]:\n",
    "            merged_df = orig.join(noised, on=index_cols[query_ind], suffix='_noised')\n",
    "        else:\n",
    "            merged_df = orig.join(noised, suffix='_noised', how='cross')\n",
    "        suffix1 = ''\n",
    "        suffix2 = '_noised'\n",
    "        cols_with_suffixes = [col for col in merged_df.columns if suffix1 in col or suffix2 in col]\n",
    "\n",
    "        base_names = set([col.replace(suffix1, '').replace(suffix2, '') for col in cols_with_suffixes])\n",
    "        for base_name in base_names:\n",
    "            nulls_exist = False\n",
    "            null_inds, null_vals = [], []\n",
    "\n",
    "            orig = base_name + suffix1\n",
    "            noised = base_name + suffix2\n",
    "            if orig in merged_df.columns and noised in merged_df.columns:\n",
    "                rel_errors = []\n",
    "                for ind in range(len(merged_df[orig])):\n",
    "                    if query_ind in scale_required:\n",
    "                        const = 2 # subsampling scaling\n",
    "                    else:\n",
    "                        const = 1\n",
    "                    noised_vals = [merged_df[noised][ind][tmp_ind] for tmp_ind in range(\n",
    "                        len(merged_df[noised][ind])) if merged_df[noised][ind][tmp_ind] is not None]\n",
    "                    if len(noised_vals) != 1000 and len(noised_vals) != 0:\n",
    "                        print('reached', query_ind)\n",
    "                    new = np.average(\n",
    "                        [100*abs(\n",
    "                            const*noised_vals[tmp_ind] - merged_df[orig][ind]\n",
    "                            ) / merged_df[orig][ind] for tmp_ind in range(\n",
    "                                len(noised_vals))]\n",
    "                    )\n",
    "                    rel_errors.append(new)\n",
    "                merged_df = merged_df.with_columns(pl.Series('pct_diff_' + base_name, rel_errors))\n",
    "                merged_df = merged_df.with_columns(pl.Series('mi', [mi]*len(rel_errors)))\n",
    "                merged_df = merged_df.with_columns(pl.Series('m', [m]*len(rel_errors)))\n",
    "        dfs.append(merged_df)\n",
    "    pct_diff_columns = [col for col in dfs[0].columns if col.startswith('pct_diff_')]\n",
    "    m_diffs = get_m_diffs(dfs, index_cols[query_ind], pct_diff_columns)\n",
    "    rel_results = [col for col in m_diffs.columns if col.startswith('m_diff')]\n",
    "    df = m_diffs[rel_results]\n",
    "    global_min = df.select(pl.min_horizontal(df.columns)).min().item()\n",
    "    global_max = df.select(pl.max_horizontal(df.columns)).max().item()\n",
    "    print(query_ind, global_max, global_min)\n",
    "    if query_ind == 8:\n",
    "        print(m_diffs)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc5648d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
