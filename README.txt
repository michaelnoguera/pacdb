All input data is in ./data. Currently we only use the student_performance dataset.

All outputs are in ./outputs.
- outputs/dp_results.parquet is generated by dp.ipynb
- outputs/dp_errors.parquet is separately calculated in pac-student_performance-sparkless.ipynb,
  using the same code as is used to compute the PAC errors

Use dp.ipynb to import Chai's DP data after copying the DP parquet output files
into the dp/{date} folder (create the folder if needed). This will output 
`./outputs/dp_results.parquet` which is read by pac-student_performance-sparkless.ipynb.

All my analysis is in pac-student_performance-sparkless.ipynb.
If you set GENERATE=True, then new data will be generated. It will be saved in various
files in outputs/pac-student_performance-sparkless. If GENERATE=False, then the data
from these files will be used.
You should be able to hit "run all" and all cells should run correctly. I am double-checking
this by clearing all outputs and re-running fresh before each commit, so all commits 
should run without errors.

The graphs are located in outputs/pac-student_performance-sparkless.


Setup:
python3.11 -m venv .venv
source .venv/bin/activate
pip3 install -r requirements.txt

then make sure that you are using jupyter kernel at .venv/bin/jupyter