{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified TPC-H Q1 Microbenchmark\n",
    "This file is adapted to use numpy only without Spark.\n",
    "\n",
    "```sql\n",
    "select\n",
    "  sum(l_quantity) as sum_qty,\n",
    "  sum(l_extendedprice) as sum_base_price,\n",
    "  sum(l_extendedprice * (1 - l_discount)) as sum_disc_price,\n",
    "  sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) as sum_charge,\n",
    "  avg(l_quantity) as avg_qty,\n",
    "  avg(l_extendedprice) as avg_price,\n",
    "  avg(l_discount) as avg_disc,\n",
    "  count(*) as count_order\n",
    "from\n",
    "  lineitem\n",
    "where\n",
    "  l_shipdate <= '1998-09-02'\n",
    "  and l_returnflag = 'A'\n",
    "  and l_linestatus = 'F'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE = True, so we will generate new samples.\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT = 'pac-q1-svd'\n",
    "OUTPUT_DIR = f'./outputs/{EXPERIMENT}'\n",
    "GENERATE = True\n",
    "USE_EVEN_NUMBER_OF_INPUT_ROWS = False\n",
    "SEED_RANDOM_NUMBER_GENERATOR = True\n",
    "\n",
    "SAMPLING_METHOD = 'poisson' # 'poisson' or 'half'\n",
    "\n",
    "if GENERATE:\n",
    "    print(\"GENERATE = True, so we will generate new samples.\")\n",
    "else:\n",
    "    print(\"GENERATE = False, so we will load saved output from files rather than recomputing.\")\n",
    "\n",
    "import os\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running PAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "if SEED_RANDOM_NUMBER_GENERATOR:\n",
    "    np.random.seed(0)\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import concurrent.futures\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pickle\n",
    "from numpy.random import laplace\n",
    "from functools import reduce\n",
    "import operator\n",
    "from IPython.display import display, HTML\n",
    "from datetime import date\n",
    "from scipy import special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mayuri's conversion functions between DP epsilon and PAC MI using posterior advantage for equivalence\n",
    "def calc_posterior(mi, prior=0.5, prec = 100000):\n",
    "    test_vals = [x / prec for x in range(1, prec)]\n",
    "    max_t = None\n",
    "    for t in test_vals:\n",
    "        if t*np.log(t/prior)+(1-t)*np.log((1-t)/(1-prior)) <= mi:\n",
    "            if  max_t is None or t > max_t:\n",
    "                max_t = t\n",
    "    return max_t\n",
    "\n",
    "def dp_epsilon_to_posterior_success(epsilon):\n",
    "    return 1 - 1./(1+np.exp(epsilon))\n",
    "\n",
    "def dp_ps_to_epsilon(ps):\n",
    "    return np.log(ps / (1-ps))\n",
    "\n",
    "# example usage:\n",
    "# dp_ps_to_epsilon(calc_posterior(1/256.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600572, 16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Data Setup\n",
    "#por_df = pq.read_table(f\"./data/student_performance/student-por.parquet\").to_pandas()\n",
    "lineitem_df = pd.read_parquet('data/tpch/lineitem.parquet')\n",
    "\n",
    "lineitem_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lineitem_df['l_linestatus'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147790, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3774200.0,\n",
       " 5320753880.69,\n",
       " 5054096266.6828,\n",
       " 5256751331.449234,\n",
       " 25.537587116854997,\n",
       " 36002.12382901414,\n",
       " 0.05014459706340077,\n",
       " 147790.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def runquery(lineitem_df: DataFrame) -> int:\n",
    "    # 1. Filter lineitem rows where commit date is before receipt date.\n",
    "    lineitem_filtered = lineitem_df[\n",
    "        (lineitem_df['l_shipdate'] <= date(1998, 9, 2)) &\n",
    "        (lineitem_df['l_returnflag'] == 'A') &\n",
    "        (lineitem_df['l_linestatus'] == 'F')\n",
    "    ]\n",
    "    print(lineitem_filtered.shape)\n",
    "\n",
    "    # 2. Pre-compute\n",
    "    discounted_price = lineitem_filtered['l_extendedprice'] * (1 - lineitem_filtered['l_discount'])\n",
    "    charged_price = discounted_price * (1 + lineitem_filtered['l_tax'])\n",
    "\n",
    "    # 3. Get aggregations\n",
    "    aggregated_result = [\n",
    "        float(lineitem_filtered['l_quantity'].sum()),       # sum_qty\n",
    "        float(lineitem_filtered['l_extendedprice'].sum()),  # sum_base_price\n",
    "        float(discounted_price.sum()),                      # sum_disc_price\n",
    "        float(charged_price.sum()),                         # sum_charge\n",
    "        float(lineitem_filtered['l_quantity'].mean()),      # avg_qty\n",
    "        float(lineitem_filtered['l_extendedprice'].mean()), # avg_price\n",
    "        float(lineitem_filtered['l_discount'].mean()),      # avg_disc\n",
    "        float(len(lineitem_filtered))                       # count_order (faster than .count())\n",
    "    ]\n",
    "\n",
    "    # print(aggregated_result)\n",
    "\n",
    "    return aggregated_result\n",
    "runquery(lineitem_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147790, 16)\n"
     ]
    }
   ],
   "source": [
    "### Query Setup\n",
    "SAMPLES = 100\n",
    "assert SAMPLES % 2 == 0, \"We need an even number of samples for paired sampling.\"\n",
    "number_of_pairs = SAMPLES // 2\n",
    "\n",
    "OUTPUT_COLS = ['sum_qty', 'sum_base_price', 'sum_disc_price', 'sum_charge', 'avg_qty', 'avg_price', 'avg_disc', 'count_order']\n",
    "\n",
    "true_result = np.array(runquery(lineitem_df)) # Save the true result of the query for later\n",
    "#true_result = np.divide(true_result, 2) # manually correct count = count * 2\n",
    "\n",
    "number_of_contributing_rows = 147790  # hardcode number of eligible rows\n",
    "\n",
    "def poisson_paired_sample(df: DataFrame) -> Tuple[DataFrame, DataFrame]:\n",
    "    \"\"\"\n",
    "    This will select a subset of indices, where each index is selected with probability 0.5.\n",
    "    The first result is the dataframe composed of the selected rows.\n",
    "    The second result is the complement / the dataframe composed of the rows that were not selected.\n",
    "    \"\"\"\n",
    "    mask = np.random.random_sample(len(df)) < 0.5  # Generates a bitmask of length df.shape[0] where each bit is 1 with probability 0.5\n",
    "    selected = df[mask]\n",
    "    not_selected = df[~mask]\n",
    "    return selected, not_selected\n",
    "\n",
    "def half_paired_sample(df: DataFrame) -> Tuple[DataFrame, DataFrame]:\n",
    "    \"\"\"\n",
    "    This will select half of the row indices from the dataframe at random.\n",
    "    The first result is the dataframe composed of the selected rows.\n",
    "    The second result is the complement / the dataframe composed of the rows that were not selected.\n",
    "    \"\"\"\n",
    "    indices = np.random.choice(df.index, size=(df.shape[0] // 2), replace=False)\n",
    "    not_indices = list(set(df.index) - set(indices))\n",
    "    selected: DataFrame = df.loc[indices]\n",
    "    not_selected: DataFrame = df.loc[not_indices]\n",
    "    return (selected, not_selected)\n",
    "\n",
    "def sample_using_chosen_method(df: DataFrame) -> Tuple[DataFrame, DataFrame]:\n",
    "    if SAMPLING_METHOD == 'poisson':\n",
    "        return poisson_paired_sample(df)\n",
    "    elif SAMPLING_METHOD == 'half':\n",
    "        return half_paired_sample(df)\n",
    "\n",
    "def generate_samples(laplace_lambda: float = 1.0, alpha: int = 10) -> List[np.ndarray]:\n",
    "    # Apply thresholding: if there are less than alpha samples\n",
    "    # (with some Laplacian noise), then we don't subsample and return None.\n",
    "    laplace_noise: float = np.random.laplace(scale=laplace_lambda)\n",
    "\n",
    "    if number_of_contributing_rows + laplace_noise < alpha:  # if we don't get enough results from the query\n",
    "        print(\"There are not enough rows contributing to the result for PAC to be meaningful.\")\n",
    "        return []\n",
    "    \n",
    "    number_of_pairs = SAMPLES // 2\n",
    "    out_np: List[np.ndarray] = []\n",
    "    for i in range(number_of_pairs):\n",
    "        print(f'iteration : {i}')\n",
    "        for temp_df in sample_using_chosen_method(lineitem_df.reset_index(drop=True)):  # reset index to sequential\n",
    "            out = runquery(temp_df)\n",
    "            # double the sums and counts, avg stays the same\n",
    "            out[0] *= 2\n",
    "            out[1] *= 2\n",
    "            out[2] *= 2\n",
    "            out[3] *= 2\n",
    "            out[7] *= 2\n",
    "            # for a 2d array, flatten it\n",
    "            out_np.append(np.array(out))\n",
    "    # Debug: SVD new (not needed I think??)\n",
    "    # out_np = reduce(operator.iconcat, out_np, [])\n",
    "\n",
    "    return out_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 0\n",
      "(73797, 16)\n",
      "(73993, 16)\n",
      "iteration : 1\n",
      "(73344, 16)\n",
      "(74446, 16)\n",
      "iteration : 2\n",
      "(73736, 16)\n",
      "(74054, 16)\n",
      "iteration : 3\n",
      "(73859, 16)\n",
      "(73931, 16)\n",
      "iteration : 4\n",
      "(73998, 16)\n",
      "(73792, 16)\n",
      "iteration : 5\n",
      "(73939, 16)\n",
      "(73851, 16)\n",
      "iteration : 6\n",
      "(74071, 16)\n",
      "(73719, 16)\n",
      "iteration : 7\n",
      "(73568, 16)\n",
      "(74222, 16)\n",
      "iteration : 8\n",
      "(73928, 16)\n",
      "(73862, 16)\n",
      "iteration : 9\n",
      "(73906, 16)\n",
      "(73884, 16)\n",
      "iteration : 10\n",
      "(74021, 16)\n",
      "(73769, 16)\n",
      "iteration : 11\n",
      "(73704, 16)\n",
      "(74086, 16)\n",
      "iteration : 12\n",
      "(73901, 16)\n",
      "(73889, 16)\n",
      "iteration : 13\n",
      "(73631, 16)\n",
      "(74159, 16)\n",
      "iteration : 14\n",
      "(73795, 16)\n",
      "(73995, 16)\n",
      "iteration : 15\n",
      "(73759, 16)\n",
      "(74031, 16)\n",
      "iteration : 16\n",
      "(74153, 16)\n",
      "(73637, 16)\n",
      "iteration : 17\n",
      "(73863, 16)\n",
      "(73927, 16)\n",
      "iteration : 18\n",
      "(73810, 16)\n",
      "(73980, 16)\n",
      "iteration : 19\n",
      "(74037, 16)\n",
      "(73753, 16)\n",
      "iteration : 20\n",
      "(74019, 16)\n",
      "(73771, 16)\n",
      "iteration : 21\n",
      "(74413, 16)\n",
      "(73377, 16)\n",
      "iteration : 22\n",
      "(73605, 16)\n",
      "(74185, 16)\n",
      "iteration : 23\n",
      "(73966, 16)\n",
      "(73824, 16)\n",
      "iteration : 24\n",
      "(74081, 16)\n",
      "(73709, 16)\n",
      "iteration : 25\n",
      "(73876, 16)\n",
      "(73914, 16)\n",
      "iteration : 26\n",
      "(73905, 16)\n",
      "(73885, 16)\n",
      "iteration : 27\n",
      "(74123, 16)\n",
      "(73667, 16)\n",
      "iteration : 28\n",
      "(73823, 16)\n",
      "(73967, 16)\n",
      "iteration : 29\n",
      "(74126, 16)\n",
      "(73664, 16)\n",
      "iteration : 30\n",
      "(73878, 16)\n",
      "(73912, 16)\n",
      "iteration : 31\n",
      "(73537, 16)\n",
      "(74253, 16)\n",
      "iteration : 32\n",
      "(73977, 16)\n",
      "(73813, 16)\n",
      "iteration : 33\n",
      "(74170, 16)\n",
      "(73620, 16)\n",
      "iteration : 34\n",
      "(73993, 16)\n",
      "(73797, 16)\n",
      "iteration : 35\n",
      "(74124, 16)\n",
      "(73666, 16)\n",
      "iteration : 36\n",
      "(73751, 16)\n",
      "(74039, 16)\n",
      "iteration : 37\n",
      "(73949, 16)\n",
      "(73841, 16)\n",
      "iteration : 38\n",
      "(73449, 16)\n",
      "(74341, 16)\n",
      "iteration : 39\n",
      "(74045, 16)\n",
      "(73745, 16)\n",
      "iteration : 40\n",
      "(73715, 16)\n",
      "(74075, 16)\n",
      "iteration : 41\n",
      "(73932, 16)\n",
      "(73858, 16)\n",
      "iteration : 42\n",
      "(73816, 16)\n",
      "(73974, 16)\n",
      "iteration : 43\n",
      "(73970, 16)\n",
      "(73820, 16)\n",
      "iteration : 44\n",
      "(73995, 16)\n",
      "(73795, 16)\n",
      "iteration : 45\n",
      "(74138, 16)\n",
      "(73652, 16)\n",
      "iteration : 46\n",
      "(73747, 16)\n",
      "(74043, 16)\n",
      "iteration : 47\n",
      "(74090, 16)\n",
      "(73700, 16)\n",
      "iteration : 48\n",
      "(73514, 16)\n",
      "(74276, 16)\n",
      "iteration : 49\n",
      "(73865, 16)\n",
      "(73925, 16)\n"
     ]
    }
   ],
   "source": [
    "out_np = generate_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions: int = len(out_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_np_2darr = [np.atleast_2d(o) for o in out_np] # make sure all the DF -> np.ndarray conversions result in 2d arrays\n",
    "est_y: np.ndarray = np.stack(out_np_2darr, axis=-1).reshape(dimensions, len(out_np))  # shape (dimensions, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57188321.522798434"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = np.var(est_y, axis=1)\n",
    "\n",
    "np.sum(np.sqrt(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33873553.42140998"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_var = np.linalg.eig(np.cov(est_y))[0]\n",
    "\n",
    "np.sum(np.sqrt(proj_var))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
