{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/14 12:15:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/03/14 12:15:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import lower, col, count, concat_ws\n",
    "from pyspark.sql.types import Row\n",
    "from pyspark import RDD\n",
    "from typing import List, Tuple, Callable, Dict, Optional, Any, NamedTuple\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pacdb import PACDataFrame, Sampler, DataFrameSampler, SamplerOptions, minimal_permutation_distance\n",
    "\n",
    "spark = (SparkSession.builder.appName(\"pacdb\")\n",
    "         .config(\"spark.executor.memory\", \"512M\")\n",
    "         .config(\"spark.sql.warehouse.dir\", \".spark\")\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate())\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# set font to Times New Roman\n",
    "LATEX = False\n",
    "if LATEX:\n",
    "    mpl.rcParams['text.usetex'] = True\n",
    "    mpl.rcParams[\"font.family\"] = \"serif\"\n",
    "    mpl.rcParams[\"font.serif\"] = \"Times\"\n",
    "else:\n",
    "    mpl.rcParams['text.usetex'] = False\n",
    "    mpl.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "    mpl.rcParams[\"mathtext.fontset\"] = \"stix\"\n",
    "    \n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "mpl.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "mpl.rcParams['axes.titleweight'] = 'bold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lung_df = spark.read.parquet(\"./data/lung.parquet\")\n",
    "#lung_df.write.saveAsTable(\"lung\", mode=\"overwrite\") # for SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 12:15:28 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/03/14 12:15:28 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "24/03/14 12:15:31 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "24/03/14 12:15:31 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore michael@10.0.0.4\n",
      "24/03/14 12:15:32 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "24/03/14 12:15:34 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/03/14 12:15:36 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "24/03/14 12:15:37 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "24/03/14 12:15:37 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/03/14 12:15:37 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
     ]
    }
   ],
   "source": [
    "# Split the lung table into multiple tables over Patient Id\n",
    "identity_df: DataFrame = lung_df.select(\"Name\", \"index\", \"Patient Id\", \"Age\", \"Gender\")\n",
    "identity_df.write.saveAsTable(\"identity\", mode=\"overwrite\")\n",
    "\n",
    "symptoms_df: DataFrame = lung_df.select(\"Patient Id\", \"Chest Pain\", \"Coughing of Blood\", \"Fatigue\", \"Weight Loss\", \"Shortness of Breath\", \"Wheezing\", \"Swallowing Difficulty\", \"Clubbing of Finger Nails\", \"Frequent Cold\", \"Dry Cough\", \"Snoring\")\n",
    "symptoms_df.write.saveAsTable(\"symptoms\", mode=\"overwrite\")\n",
    "\n",
    "risk_factors_df: DataFrame = lung_df.select(\"Patient Id\", \"Air Pollution\", \"Alcohol use\", \"Dust Allergy\", \"Occupational Hazards\", \"Genetic Risk\", \"Chronic Lung Disease\", \"Balanced Diet\", \"Obesity\", \"Smoking\", \"Passive Smoker\")\n",
    "risk_factors_df.write.saveAsTable(\"risk_factors\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_Group</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age_Group  Count\n",
       "0         10     28\n",
       "1         20    106\n",
       "2         30    222\n",
       "3         40    120\n",
       "4         50     30\n",
       "5         60     31\n",
       "6         70     10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of patients in each age group with chest pain who are smokers\n",
    "spark.sql(\"\"\"\n",
    "        SELECT FLOOR(identity.Age / 10) * 10 AS Age_Group, COUNT(*) AS Count\n",
    "        FROM identity\n",
    "        JOIN symptoms ON identity.`Patient Id` = symptoms.`Patient Id`\n",
    "        JOIN risk_factors ON identity.`Patient Id` = risk_factors.`Patient Id`\n",
    "        WHERE risk_factors.Smoking >= 3\n",
    "          AND symptoms.`Chest Pain` > 1\n",
    "        GROUP BY FLOOR(identity.Age / 10) * 10\n",
    "        ORDER BY Age_Group\n",
    "        \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do all joins and filters first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Do all joins, etc. to get the data you want into a single Spark DataFrame. Turn it into a PACDataFrame.\n",
    "spark_df: DataFrame = (identity_df\n",
    "                       .join(symptoms_df.filter(symptoms_df[\"Chest Pain\"] > 1), \"Patient Id\") # First do all the joins\n",
    "                       .join(risk_factors_df.filter(risk_factors_df[\"Smoking\"] >= 3) , \"Patient Id\") # N\n",
    "                      )\n",
    "pac_df: PACDataFrame = PACDataFrame(spark_df)\n",
    "               \n",
    "# Define your query as a function that takes a DataFrame and returns (for now) an integer\n",
    "def A(x: DataFrame) -> int:\n",
    "    \"\"\"Function to make private\"\"\"\n",
    "    y = (x.withColumn(\"Age_Group\", (x[\"Age\"] / 10).cast(\"int\") * 10)\n",
    "          .groupBy(\"Age_Group\")\n",
    "          .count()\n",
    "          .orderBy(\"Age_Group\"))\n",
    "    return y\n",
    "\n",
    "# Attach the predicate function to the PACDataFrame\n",
    "pac_df = pac_df.withQuery(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pacdb.main.PACDataFrame at 0x29ea374d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Sampling\n",
    "# Set sampler options on the PACDataFrame\n",
    "pac_df = (pac_df.withSamplerOptions(\n",
    "                SamplerOptions(\n",
    "                    withReplacement=False, \n",
    "                    fraction=0.5\n",
    "                ))\n",
    "                .setNumberOfTrials(200)\n",
    "                .setMutualInformationBound(1./8))\n",
    "\n",
    "pac_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subsample: 100%|██████████| 400/400 [00:01<00:00, 285.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[DataFrame[Patient Id: string, Name: string, index: bigint, Age: bigint, Gender: bigint, Chest Pain: bigint, Coughing of Blood: bigint, Fatigue: bigint, Weight Loss: bigint, Shortness of Breath: bigint, Wheezing: bigint, Swallowing Difficulty: bigint, Clubbing of Finger Nails: bigint, Frequent Cold: bigint, Dry Cough: bigint, Snoring: bigint, Air Pollution: bigint, Alcohol use: bigint, Dust Allergy: bigint, Occupational Hazards: bigint, Genetic Risk: bigint, Chronic Lung Disease: bigint, Balanced Diet: bigint, Obesity: bigint, Smoking: bigint, Passive Smoker: bigint],\n",
       " DataFrame[Patient Id: string, Name: string, index: bigint, Age: bigint, Gender: bigint, Chest Pain: bigint, Coughing of Blood: bigint, Fatigue: bigint, Weight Loss: bigint, Shortness of Breath: bigint, Wheezing: bigint, Swallowing Difficulty: bigint, Clubbing of Finger Nails: bigint, Frequent Cold: bigint, Dry Cough: bigint, Snoring: bigint, Air Pollution: bigint, Alcohol use: bigint, Dust Allergy: bigint, Occupational Hazards: bigint, Genetic Risk: bigint, Chronic Lung Disease: bigint, Balanced Diet: bigint, Obesity: bigint, Smoking: bigint, Passive Smoker: bigint],\n",
       " DataFrame[Patient Id: string, Name: string, index: bigint, Age: bigint, Gender: bigint, Chest Pain: bigint, Coughing of Blood: bigint, Fatigue: bigint, Weight Loss: bigint, Shortness of Breath: bigint, Wheezing: bigint, Swallowing Difficulty: bigint, Clubbing of Finger Nails: bigint, Frequent Cold: bigint, Dry Cough: bigint, Snoring: bigint, Air Pollution: bigint, Alcohol use: bigint, Dust Allergy: bigint, Occupational Hazards: bigint, Genetic Risk: bigint, Chronic Lung Disease: bigint, Balanced Diet: bigint, Obesity: bigint, Smoking: bigint, Passive Smoker: bigint]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac_df._subsample()\n",
    "X = pac_df.X\n",
    "pac_df.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measure Stability: 100%|██████████| 400/400 [00:16<00:00, 23.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[DataFrame[Age_Group: int, count: bigint],\n",
       " DataFrame[Age_Group: int, count: bigint],\n",
       " DataFrame[Age_Group: int, count: bigint]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Measure Stability\n",
    "\n",
    "# Eventually this should become something like PACDataFrame.analyze()\n",
    "# The challenge is how to handle the way that sampling affects the outcome of the predicate\n",
    "# for all predicate types: i.e. we need to multiply to cancel out sampling rate for count and sum\n",
    "\n",
    "pac_df._measure_stability()\n",
    "Y = pac_df.Y\n",
    "Y_pairs = pac_df.Y_pairs\n",
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_Group</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age_Group  count\n",
       "0         10     12\n",
       "1         20     49\n",
       "2         30    103\n",
       "3         40     59\n",
       "4         50     21\n",
       "5         60     15\n",
       "6         70      4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0][0].toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Estimate Noise\n",
    "c = 0.001\n",
    "max_mi = 1/8  # 2 * v\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# find paired distances between dataframes: take count column as vector\n",
    "avg_dist = 0\n",
    "tau = len(np.array(Y_pairs[0][0].toPandas()[\"count\"]))\n",
    "for trial in range(trials):\n",
    "    y1, y2 = Y_pairs[trial][0], Y_pairs[trial][1]\n",
    "    # get the count column as an array of ints\n",
    "    y1: np.array = np.array(y1.toPandas()[\"count\"])\n",
    "    y2: np.array = np.array(y2.toPandas()[\"count\"])\n",
    "    # compute the distance between the two vectors\n",
    "    dist = 0.\n",
    "\n",
    "    for ind in range(tau):\n",
    "        dist += np.linalg.norm(np.array(y1[ind]) - np.array(y2[ind]))**2 / tau\n",
    "    avg_dist += dist\n",
    "    #ys.append((y1, y2))\n",
    "\n",
    "avg_dist /= trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paclib\n",
    "# At different levels of MI, compute noise to add\n",
    "noise_params = []\n",
    "for max_mi in [1/64, 1/32, 1/16, 1/8, 1/4, 1/2, 1., 2., 4.]:\n",
    "    print(f\"avg_dist: {avg_dist}, c: {c}, max_mi: {max_mi:8} => {paclib.noise_to_add(avg_dist, c, max_mi)}\")\n",
    "    noise_params.append([\n",
    "        max_mi, \n",
    "        paclib.noise_to_add(avg_dist, c, max_mi).mean, \n",
    "        paclib.noise_to_add(avg_dist, c, max_mi).variance\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Noised Release\n",
    "\n",
    "# obtain one more sample to use for noised release\n",
    "Yj = pac_df._applyPredicate(pac_df.sample())\n",
    "Yj_arr: np.array = np.array(Yj.toPandas()[\"count\"])\n",
    "print(Yj_arr)\n",
    "\n",
    "c = 0.001\n",
    "mi = 1/16\n",
    "\n",
    "noise_to_add = paclib.noise_to_add(avg_dist, c, mi).sample()\n",
    "print(noise_to_add)\n",
    "\n",
    "noised_Yj = Yj_arr + noise_to_add\n",
    "noised_Yj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
